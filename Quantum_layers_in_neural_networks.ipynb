{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDfU8NjIjd99",
        "outputId": "d58d5fb4-bede-4180-9e5b-f6e590894a96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.33.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.2.1)\n",
            "Requirement already satisfied: rustworkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version>=2.7 in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.10.0)\n",
            "Requirement already satisfied: autoray>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.6.7)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.33 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.33.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.5.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = np.array(iris['data'], requires_grad=True)\n",
        "y = np.array(iris['target'], requires_grad=True)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrUCrWOXFoVu",
        "outputId": "cc35244b-166d-4943-a8c7-7e3bb7eede01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5.1, 3.5, 1.4, 0.2],\n",
              "         [4.9, 3. , 1.4, 0.2],\n",
              "         [4.7, 3.2, 1.3, 0.2],\n",
              "         [4.6, 3.1, 1.5, 0.2],\n",
              "         [5. , 3.6, 1.4, 0.2],\n",
              "         [5.4, 3.9, 1.7, 0.4],\n",
              "         [4.6, 3.4, 1.4, 0.3],\n",
              "         [5. , 3.4, 1.5, 0.2],\n",
              "         [4.4, 2.9, 1.4, 0.2],\n",
              "         [4.9, 3.1, 1.5, 0.1],\n",
              "         [5.4, 3.7, 1.5, 0.2],\n",
              "         [4.8, 3.4, 1.6, 0.2],\n",
              "         [4.8, 3. , 1.4, 0.1],\n",
              "         [4.3, 3. , 1.1, 0.1],\n",
              "         [5.8, 4. , 1.2, 0.2],\n",
              "         [5.7, 4.4, 1.5, 0.4],\n",
              "         [5.4, 3.9, 1.3, 0.4],\n",
              "         [5.1, 3.5, 1.4, 0.3],\n",
              "         [5.7, 3.8, 1.7, 0.3],\n",
              "         [5.1, 3.8, 1.5, 0.3],\n",
              "         [5.4, 3.4, 1.7, 0.2],\n",
              "         [5.1, 3.7, 1.5, 0.4],\n",
              "         [4.6, 3.6, 1. , 0.2],\n",
              "         [5.1, 3.3, 1.7, 0.5],\n",
              "         [4.8, 3.4, 1.9, 0.2],\n",
              "         [5. , 3. , 1.6, 0.2],\n",
              "         [5. , 3.4, 1.6, 0.4],\n",
              "         [5.2, 3.5, 1.5, 0.2],\n",
              "         [5.2, 3.4, 1.4, 0.2],\n",
              "         [4.7, 3.2, 1.6, 0.2],\n",
              "         [4.8, 3.1, 1.6, 0.2],\n",
              "         [5.4, 3.4, 1.5, 0.4],\n",
              "         [5.2, 4.1, 1.5, 0.1],\n",
              "         [5.5, 4.2, 1.4, 0.2],\n",
              "         [4.9, 3.1, 1.5, 0.2],\n",
              "         [5. , 3.2, 1.2, 0.2],\n",
              "         [5.5, 3.5, 1.3, 0.2],\n",
              "         [4.9, 3.6, 1.4, 0.1],\n",
              "         [4.4, 3. , 1.3, 0.2],\n",
              "         [5.1, 3.4, 1.5, 0.2],\n",
              "         [5. , 3.5, 1.3, 0.3],\n",
              "         [4.5, 2.3, 1.3, 0.3],\n",
              "         [4.4, 3.2, 1.3, 0.2],\n",
              "         [5. , 3.5, 1.6, 0.6],\n",
              "         [5.1, 3.8, 1.9, 0.4],\n",
              "         [4.8, 3. , 1.4, 0.3],\n",
              "         [5.1, 3.8, 1.6, 0.2],\n",
              "         [4.6, 3.2, 1.4, 0.2],\n",
              "         [5.3, 3.7, 1.5, 0.2],\n",
              "         [5. , 3.3, 1.4, 0.2],\n",
              "         [7. , 3.2, 4.7, 1.4],\n",
              "         [6.4, 3.2, 4.5, 1.5],\n",
              "         [6.9, 3.1, 4.9, 1.5],\n",
              "         [5.5, 2.3, 4. , 1.3],\n",
              "         [6.5, 2.8, 4.6, 1.5],\n",
              "         [5.7, 2.8, 4.5, 1.3],\n",
              "         [6.3, 3.3, 4.7, 1.6],\n",
              "         [4.9, 2.4, 3.3, 1. ],\n",
              "         [6.6, 2.9, 4.6, 1.3],\n",
              "         [5.2, 2.7, 3.9, 1.4],\n",
              "         [5. , 2. , 3.5, 1. ],\n",
              "         [5.9, 3. , 4.2, 1.5],\n",
              "         [6. , 2.2, 4. , 1. ],\n",
              "         [6.1, 2.9, 4.7, 1.4],\n",
              "         [5.6, 2.9, 3.6, 1.3],\n",
              "         [6.7, 3.1, 4.4, 1.4],\n",
              "         [5.6, 3. , 4.5, 1.5],\n",
              "         [5.8, 2.7, 4.1, 1. ],\n",
              "         [6.2, 2.2, 4.5, 1.5],\n",
              "         [5.6, 2.5, 3.9, 1.1],\n",
              "         [5.9, 3.2, 4.8, 1.8],\n",
              "         [6.1, 2.8, 4. , 1.3],\n",
              "         [6.3, 2.5, 4.9, 1.5],\n",
              "         [6.1, 2.8, 4.7, 1.2],\n",
              "         [6.4, 2.9, 4.3, 1.3],\n",
              "         [6.6, 3. , 4.4, 1.4],\n",
              "         [6.8, 2.8, 4.8, 1.4],\n",
              "         [6.7, 3. , 5. , 1.7],\n",
              "         [6. , 2.9, 4.5, 1.5],\n",
              "         [5.7, 2.6, 3.5, 1. ],\n",
              "         [5.5, 2.4, 3.8, 1.1],\n",
              "         [5.5, 2.4, 3.7, 1. ],\n",
              "         [5.8, 2.7, 3.9, 1.2],\n",
              "         [6. , 2.7, 5.1, 1.6],\n",
              "         [5.4, 3. , 4.5, 1.5],\n",
              "         [6. , 3.4, 4.5, 1.6],\n",
              "         [6.7, 3.1, 4.7, 1.5],\n",
              "         [6.3, 2.3, 4.4, 1.3],\n",
              "         [5.6, 3. , 4.1, 1.3],\n",
              "         [5.5, 2.5, 4. , 1.3],\n",
              "         [5.5, 2.6, 4.4, 1.2],\n",
              "         [6.1, 3. , 4.6, 1.4],\n",
              "         [5.8, 2.6, 4. , 1.2],\n",
              "         [5. , 2.3, 3.3, 1. ],\n",
              "         [5.6, 2.7, 4.2, 1.3],\n",
              "         [5.7, 3. , 4.2, 1.2],\n",
              "         [5.7, 2.9, 4.2, 1.3],\n",
              "         [6.2, 2.9, 4.3, 1.3],\n",
              "         [5.1, 2.5, 3. , 1.1],\n",
              "         [5.7, 2.8, 4.1, 1.3],\n",
              "         [6.3, 3.3, 6. , 2.5],\n",
              "         [5.8, 2.7, 5.1, 1.9],\n",
              "         [7.1, 3. , 5.9, 2.1],\n",
              "         [6.3, 2.9, 5.6, 1.8],\n",
              "         [6.5, 3. , 5.8, 2.2],\n",
              "         [7.6, 3. , 6.6, 2.1],\n",
              "         [4.9, 2.5, 4.5, 1.7],\n",
              "         [7.3, 2.9, 6.3, 1.8],\n",
              "         [6.7, 2.5, 5.8, 1.8],\n",
              "         [7.2, 3.6, 6.1, 2.5],\n",
              "         [6.5, 3.2, 5.1, 2. ],\n",
              "         [6.4, 2.7, 5.3, 1.9],\n",
              "         [6.8, 3. , 5.5, 2.1],\n",
              "         [5.7, 2.5, 5. , 2. ],\n",
              "         [5.8, 2.8, 5.1, 2.4],\n",
              "         [6.4, 3.2, 5.3, 2.3],\n",
              "         [6.5, 3. , 5.5, 1.8],\n",
              "         [7.7, 3.8, 6.7, 2.2],\n",
              "         [7.7, 2.6, 6.9, 2.3],\n",
              "         [6. , 2.2, 5. , 1.5],\n",
              "         [6.9, 3.2, 5.7, 2.3],\n",
              "         [5.6, 2.8, 4.9, 2. ],\n",
              "         [7.7, 2.8, 6.7, 2. ],\n",
              "         [6.3, 2.7, 4.9, 1.8],\n",
              "         [6.7, 3.3, 5.7, 2.1],\n",
              "         [7.2, 3.2, 6. , 1.8],\n",
              "         [6.2, 2.8, 4.8, 1.8],\n",
              "         [6.1, 3. , 4.9, 1.8],\n",
              "         [6.4, 2.8, 5.6, 2.1],\n",
              "         [7.2, 3. , 5.8, 1.6],\n",
              "         [7.4, 2.8, 6.1, 1.9],\n",
              "         [7.9, 3.8, 6.4, 2. ],\n",
              "         [6.4, 2.8, 5.6, 2.2],\n",
              "         [6.3, 2.8, 5.1, 1.5],\n",
              "         [6.1, 2.6, 5.6, 1.4],\n",
              "         [7.7, 3. , 6.1, 2.3],\n",
              "         [6.3, 3.4, 5.6, 2.4],\n",
              "         [6.4, 3.1, 5.5, 1.8],\n",
              "         [6. , 3. , 4.8, 1.8],\n",
              "         [6.9, 3.1, 5.4, 2.1],\n",
              "         [6.7, 3.1, 5.6, 2.4],\n",
              "         [6.9, 3.1, 5.1, 2.3],\n",
              "         [5.8, 2.7, 5.1, 1.9],\n",
              "         [6.8, 3.2, 5.9, 2.3],\n",
              "         [6.7, 3.3, 5.7, 2.5],\n",
              "         [6.7, 3. , 5.2, 2.3],\n",
              "         [6.3, 2.5, 5. , 1.9],\n",
              "         [6.5, 3. , 5.2, 2. ],\n",
              "         [6.2, 3.4, 5.4, 2.3],\n",
              "         [5.9, 3. , 5.1, 1.8]], requires_grad=True),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c83b3486-cee5-455e-f6fa-3fb64fc0127b",
        "id": "7mDVTtefwxM7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 [[0.3        0.49       0.29000003 0.5       ]\n",
            " [0.49       0.5        0.29000003 0.49000001]] 0.35658584877518806\n",
            "step 0 params [[0.3        0.49       0.29000003 0.5       ]\n",
            " [0.49       0.5        0.29000003 0.49000001]] loss 0.35658584877518806 predictions [tensor(0.70546527, requires_grad=True), tensor(0.68764913, requires_grad=True), tensor(0.70546527, requires_grad=True), tensor(0.68764913, requires_grad=True)]\n",
            "Iter:     1 | Cost: 1.1636282 | Accuracy: 1.0000000 \n",
            "step 1 [[0.3        0.49425228 0.29451558 0.5       ]\n",
            " [0.49425941 0.5        0.29451558 0.49434707]] 1.222358361430949\n",
            "step 1 params [[0.3        0.49425228 0.29451558 0.5       ]\n",
            " [0.49425941 0.5        0.29451558 0.49434707]] loss 1.222358361430949 predictions [tensor(0.70313793, requires_grad=True), tensor(0.6848106, requires_grad=True), tensor(0.70313793, requires_grad=True), tensor(0.6848106, requires_grad=True)]\n",
            "Iter:     2 | Cost: 1.1545816 | Accuracy: 1.0000000 \n",
            "step 2 [[0.3        0.49502091 0.2955271  0.5       ]\n",
            " [0.49503476 0.5        0.2955271  0.49520382]] 0.35220220859754986\n",
            "step 2 params [[0.3        0.49502091 0.2955271  0.5       ]\n",
            " [0.49503476 0.5        0.2955271  0.49520382]] loss 0.35220220859754986 predictions [tensor(0.7027022, requires_grad=True), tensor(0.68425078, requires_grad=True), tensor(0.7027022, requires_grad=True), tensor(0.68425078, requires_grad=True)]\n",
            "Iter:     3 | Cost: 1.2130210 | Accuracy: 1.0000000 \n",
            "step 3 [[0.3        0.49926405 0.29987381 0.5       ]\n",
            " [0.49928055 0.5        0.29987381 0.49948335]] 1.2130209614783634\n",
            "step 3 params [[0.3        0.49926405 0.29987381 0.5       ]\n",
            " [0.49928055 0.5        0.29987381 0.49948335]] loss 1.2130209614783634 predictions [tensor(0.70040824, requires_grad=True), tensor(0.68146669, requires_grad=True), tensor(0.70040824, requires_grad=True), tensor(0.68146669, requires_grad=True)]\n",
            "Iter:     4 | Cost: 0.3835079 | Accuracy: 1.0000000 \n",
            "step 4 [[0.3        0.50209257 0.29866599 0.5       ]\n",
            " [0.50133781 0.5        0.29866599 0.49959834]] 0.3835079052488763\n",
            "step 4 params [[0.3        0.50209257 0.29866599 0.5       ]\n",
            " [0.50133781 0.5        0.29866599 0.49959834]] loss 0.3835079052488763 predictions [tensor(0.69945193, requires_grad=True), tensor(0.68097312, requires_grad=True), tensor(0.69945193, requires_grad=True), tensor(0.68097312, requires_grad=True)]\n",
            "Iter:     5 | Cost: 0.3842324 | Accuracy: 1.0000000 \n",
            "step 5 [[0.3        0.5030599  0.29670457 0.5       ]\n",
            " [0.5017019  0.5        0.29670457 0.49853771]] 0.3574582145445693\n",
            "step 5 params [[0.3        0.5030599  0.29670457 0.5       ]\n",
            " [0.5017019  0.5        0.29670457 0.49853771]] loss 0.3574582145445693 predictions [tensor(0.6993523, requires_grad=True), tensor(0.68133628, requires_grad=True), tensor(0.6993523, requires_grad=True), tensor(0.68133628, requires_grad=True)]\n",
            "Iter:     6 | Cost: 1.2018161 | Accuracy: 1.0000000 \n",
            "step 6 [[0.3        0.50643901 0.2970607  0.5       ]\n",
            " [0.50458754 0.5        0.2970607  0.50003496]] 1.201816121062332\n",
            "step 6 params [[0.3        0.50643901 0.2970607  0.5       ]\n",
            " [0.50458754 0.5        0.2970607  0.50003496]] loss 1.201816121062332 predictions [tensor(0.69792117, requires_grad=True), tensor(0.68009953, requires_grad=True), tensor(0.69792117, requires_grad=True), tensor(0.68009953, requires_grad=True)]\n",
            "Iter:     7 | Cost: 1.1970673 | Accuracy: 1.0000000 \n",
            "step 7 [[0.3        0.50824707 0.29658629 0.5       ]\n",
            " [0.50599255 0.5        0.29658629 0.50037701]] 0.3596491252803576\n",
            "step 7 params [[0.3        0.50824707 0.29658629 0.5       ]\n",
            " [0.50599255 0.5        0.29658629 0.50037701]] loss 0.3596491252803576 predictions [tensor(0.69724851, requires_grad=True), tensor(0.67966122, requires_grad=True), tensor(0.69724851, requires_grad=True), tensor(0.67966122, requires_grad=True)]\n",
            "Iter:     8 | Cost: 1.1383762 | Accuracy: 1.0000000 \n",
            "step 8 [[0.3        0.51189984 0.29784311 0.5       ]\n",
            " [0.50930072 0.5        0.29784311 0.50263207]] 1.1948429721867726\n",
            "step 8 params [[0.3        0.51189984 0.29784311 0.5       ]\n",
            " [0.50930072 0.5        0.29784311 0.50263207]] loss 1.1948429721867726 predictions [tensor(0.69556949, requires_grad=True), tensor(0.67802285, requires_grad=True), tensor(0.69556949, requires_grad=True), tensor(0.67802285, requires_grad=True)]\n",
            "Iter:     9 | Cost: 1.1893124 | Accuracy: 1.0000000 \n",
            "step 9 [[0.3        0.51607022 0.30224785 0.5       ]\n",
            " [0.51383268 0.5        0.30224785 0.50731878]] 1.133274713878167\n",
            "step 9 params [[0.3        0.51607022 0.30224785 0.5       ]\n",
            " [0.51383268 0.5        0.30224785 0.50731878]] loss 1.133274713878167 predictions [tensor(0.69321225, requires_grad=True), tensor(0.67512615, requires_grad=True), tensor(0.69321225, requires_grad=True), tensor(0.67512615, requires_grad=True)]\n",
            "Iter:    10 | Cost: 0.3664191 | Accuracy: 1.0000000 \n",
            "step 10 [[0.3        0.51934116 0.30431257 0.5       ]\n",
            " [0.517002   0.5        0.30431257 0.50988277]] 0.39285571931707836\n",
            "step 10 params [[0.3        0.51934116 0.30431257 0.5       ]\n",
            " [0.517002   0.5        0.30431257 0.50988277]] loss 0.39285571931707836 predictions [tensor(0.69159334, requires_grad=True), tensor(0.6733716, requires_grad=True), tensor(0.69159334, requires_grad=True), tensor(0.6733716, requires_grad=True)]\n",
            "Iter:    11 | Cost: 0.3687572 | Accuracy: 1.0000000 \n",
            "step 11 [[0.3        0.52181908 0.30451967 0.5       ]\n",
            " [0.51898748 0.5        0.30451967 0.51070788]] 0.39545794517087896\n",
            "step 11 params [[0.3        0.52181908 0.30451967 0.5       ]\n",
            " [0.51898748 0.5        0.30451967 0.51070788]] loss 0.39545794517087896 predictions [tensor(0.69059227, requires_grad=True), tensor(0.67255503, requires_grad=True), tensor(0.69059227, requires_grad=True), tensor(0.67255503, requires_grad=True)]\n",
            "Iter:    12 | Cost: 1.1164353 | Accuracy: 1.0000000 \n",
            "step 12 [[0.3        0.52493822 0.30730797 0.5       ]\n",
            " [0.52227721 0.5        0.30730797 0.51378367]] 1.116435255939546\n",
            "step 12 params [[0.3        0.52493822 0.30730797 0.5       ]\n",
            " [0.52227721 0.5        0.30730797 0.51378367]] loss 1.116435255939546 predictions [tensor(0.68891912, requires_grad=True), tensor(0.67058526, requires_grad=True), tensor(0.68891912, requires_grad=True), tensor(0.67058526, requires_grad=True)]\n",
            "Iter:    13 | Cost: 1.1677023 | Accuracy: 1.0000000 \n",
            "step 13 [[0.3        0.5294228  0.31042029 0.5       ]\n",
            " [0.5267486  0.5        0.31042029 0.51753321]] 1.1677023241536197\n",
            "step 13 params [[0.3        0.5294228  0.31042029 0.5       ]\n",
            " [0.5267486  0.5        0.31042029 0.51753321]] loss 1.1677023241536197 predictions [tensor(0.68666022, requires_grad=True), tensor(0.66808227, requires_grad=True), tensor(0.68666022, requires_grad=True), tensor(0.66808227, requires_grad=True)]\n",
            "Iter:    14 | Cost: 1.1028681 | Accuracy: 1.0000000 \n",
            "step 14 [[0.3        0.53306029 0.31190753 0.5       ]\n",
            " [0.53002361 0.5        0.31190753 0.51969072]] 0.40334395168050297\n",
            "step 14 params [[0.3        0.53306029 0.31190753 0.5       ]\n",
            " [0.53002361 0.5        0.31190753 0.51969072]] loss 0.40334395168050297 predictions [tensor(0.68500712, requires_grad=True), tensor(0.66645648, requires_grad=True), tensor(0.68500712, requires_grad=True), tensor(0.66645648, requires_grad=True)]\n",
            "Iter:    15 | Cost: 0.4057804 | Accuracy: 1.0000000 \n",
            "step 15 [[0.3        0.53713813 0.3153017  0.5       ]\n",
            " [0.53427389 0.5        0.3153017  0.52352498]] 1.097981914270131\n",
            "step 15 params [[0.3        0.53713813 0.3153017  0.5       ]\n",
            " [0.53427389 0.5        0.3153017  0.52352498]] loss 1.097981914270131 predictions [tensor(0.6828795, requires_grad=True), tensor(0.66399104, requires_grad=True), tensor(0.6828795, requires_grad=True), tensor(0.66399104, requires_grad=True)]\n",
            "Iter:    16 | Cost: 1.0906175 | Accuracy: 1.0000000 \n",
            "step 16 [[0.3        0.54233924 0.31881362 0.5       ]\n",
            " [0.53946072 0.5        0.31881362 0.52781256]] 1.1484734555169875\n",
            "step 16 params [[0.3        0.54233924 0.31881362 0.5       ]\n",
            " [0.53946072 0.5        0.31881362 0.52781256]] loss 1.1484734555169875 predictions [tensor(0.68029748, requires_grad=True), tensor(0.66114591, requires_grad=True), tensor(0.68029748, requires_grad=True), tensor(0.66114591, requires_grad=True)]\n",
            "Iter:    17 | Cost: 1.1403643 | Accuracy: 1.0000000 \n",
            "step 17 [[0.3        0.54776732 0.32369767 0.5       ]\n",
            " [0.54529576 0.5        0.32369767 0.53327865]] 1.0821856873921665\n",
            "step 17 params [[0.3        0.54776732 0.32369767 0.5       ]\n",
            " [0.54529576 0.5        0.32369767 0.53327865]] loss 1.0821856873921665 predictions [tensor(0.67743037, requires_grad=True), tensor(0.65774039, requires_grad=True), tensor(0.67743037, requires_grad=True), tensor(0.65774039, requires_grad=True)]\n",
            "Iter:    18 | Cost: 0.4189450 | Accuracy: 1.0000000 \n",
            "step 18 [[0.3        0.55182201 0.32798854 0.5       ]\n",
            " [0.54985989 0.5        0.32798854 0.53788184]] 0.38944850666298636\n",
            "step 18 params [[0.3        0.55182201 0.32798854 0.5       ]\n",
            " [0.54985989 0.5        0.32798854 0.53788184]] loss 0.38944850666298636 predictions [tensor(0.67521308, requires_grad=True), tensor(0.65497864, requires_grad=True), tensor(0.67521308, requires_grad=True), tensor(0.65497864, requires_grad=True)]\n",
            "Iter:    19 | Cost: 1.1245859 | Accuracy: 1.0000000 \n",
            "step 19 [[0.3        0.55464666 0.33175513 0.5       ]\n",
            " [0.55327908 0.5        0.33175513 0.54170587]] 0.39272696158189135\n",
            "step 19 params [[0.3        0.55464666 0.33175513 0.5       ]\n",
            " [0.55327908 0.5        0.33175513 0.54170587]] loss 0.39272696158189135 predictions [tensor(0.67357266, requires_grad=True), tensor(0.65278774, requires_grad=True), tensor(0.67357266, requires_grad=True), tensor(0.65278774, requires_grad=True)]\n",
            "Iter:    20 | Cost: 1.1195479 | Accuracy: 1.0000000 \n",
            "step 20 [[0.3        0.55683179 0.33410342 0.5       ]\n",
            " [0.55570313 0.5        0.33410342 0.54415049]] 0.4265032552863242\n",
            "step 20 params [[0.3        0.55683179 0.33410342 0.5       ]\n",
            " [0.55570313 0.5        0.33410342 0.54415049]] loss 0.4265032552863242 predictions [tensor(0.67240409, requires_grad=True), tensor(0.65132151, requires_grad=True), tensor(0.67240409, requires_grad=True), tensor(0.65132151, requires_grad=True)]\n",
            "Iter:    21 | Cost: 1.0536050 | Accuracy: 1.0000000 \n",
            "step 21 [[0.3        0.55952032 0.33788498 0.5       ]\n",
            " [0.55906672 0.5        0.33788498 0.54796672]] 1.0536050058893218\n",
            "step 21 params [[0.3        0.55952032 0.33788498 0.5       ]\n",
            " [0.55906672 0.5        0.33788498 0.54796672]] loss 1.0536050058893218 predictions [tensor(0.67082725, requires_grad=True), tensor(0.64917141, requires_grad=True), tensor(0.67082725, requires_grad=True), tensor(0.64917141, requires_grad=True)]\n",
            "Iter:    22 | Cost: 1.0474575 | Accuracy: 1.0000000 \n",
            "step 22 [[0.3        0.56265742 0.34281541 0.5       ]\n",
            " [0.56323738 0.5        0.34281541 0.5528935 ]] 1.047457509096443\n",
            "step 22 params [[0.3        0.56265742 0.34281541 0.5       ]\n",
            " [0.56323738 0.5        0.34281541 0.5528935 ]] loss 1.047457509096443 predictions [tensor(0.66891688, requires_grad=True), tensor(0.64646792, requires_grad=True), tensor(0.66891688, requires_grad=True), tensor(0.64646792, requires_grad=True)]\n",
            "Iter:    23 | Cost: 1.0397811 | Accuracy: 1.0000000 \n",
            "step 23 [[0.3        0.56698621 0.34748934 0.5       ]\n",
            " [0.56824423 0.5        0.34748934 0.55798536]] 1.1053858116264026\n",
            "step 23 params [[0.3        0.56698621 0.34748934 0.5       ]\n",
            " [0.56824423 0.5        0.34748934 0.55798536]] loss 1.1053858116264026 predictions [tensor(0.66660604, requires_grad=True), tensor(0.64352791, requires_grad=True), tensor(0.66660604, requires_grad=True), tensor(0.64352791, requires_grad=True)]\n",
            "Iter:    24 | Cost: 1.0314993 | Accuracy: 1.0000000 \n",
            "step 24 [[0.3        0.57229851 0.35189744 0.5       ]\n",
            " [0.5739613  0.5        0.35189744 0.5632154 ]] 1.0984304393085051\n",
            "step 24 params [[0.3        0.57229851 0.35189744 0.5       ]\n",
            " [0.5739613  0.5        0.35189744 0.5632154 ]] loss 1.0984304393085051 predictions [tensor(0.663968, requires_grad=True), tensor(0.6404057, requires_grad=True), tensor(0.663968, requires_grad=True), tensor(0.6404057, requires_grad=True)]\n",
            "Iter:    25 | Cost: 0.4456534 | Accuracy: 1.0000000 \n",
            "step 25 [[0.3        0.57678513 0.35494736 0.5       ]\n",
            " [0.57852471 0.5        0.35494736 0.56702524]] 0.4456533954501497\n",
            "step 25 params [[0.3        0.57678513 0.35494736 0.5       ]\n",
            " [0.57852471 0.5        0.35494736 0.56702524]] loss 0.4456533954501497 predictions [tensor(0.66185638, requires_grad=True), tensor(0.63804314, requires_grad=True), tensor(0.66185638, requires_grad=True), tensor(0.63804314, requires_grad=True)]\n",
            "Iter:    26 | Cost: 1.0162302 | Accuracy: 1.0000000 \n",
            "step 26 [[0.3        0.58004413 0.35769691 0.5       ]\n",
            " [0.58199823 0.5        0.35769691 0.57020029]] 0.41270669916309977\n",
            "step 26 params [[0.3        0.58004413 0.35769691 0.5       ]\n",
            " [0.58199823 0.5        0.35769691 0.57020029]] loss 0.41270669916309977 predictions [tensor(0.66027331, requires_grad=True), tensor(0.63615983, requires_grad=True), tensor(0.66027331, requires_grad=True), tensor(0.63615983, requires_grad=True)]\n",
            "Iter:    27 | Cost: 1.0110406 | Accuracy: 1.0000000 \n",
            "step 27 [[0.3        0.58361867 0.36163646 0.5       ]\n",
            " [0.5861823  0.5        0.36163646 0.57450446]] 1.0110406003999757\n",
            "step 27 params [[0.3        0.58361867 0.36163646 0.5       ]\n",
            " [0.5861823  0.5        0.36163646 0.57450446]] loss 1.0110406003999757 predictions [tensor(0.65842511, requires_grad=True), tensor(0.6337641, requires_grad=True), tensor(0.65842511, requires_grad=True), tensor(0.6337641, requires_grad=True)]\n",
            "Iter:    28 | Cost: 0.4560785 | Accuracy: 1.0000000 \n",
            "step 28 [[0.3        0.58747489 0.36656368 0.5       ]\n",
            " [0.5909865  0.5        0.36656368 0.57975347]] 1.0044776145277858\n",
            "step 28 params [[0.3        0.58747489 0.36656368 0.5       ]\n",
            " [0.5909865  0.5        0.36656368 0.57975347]] loss 1.0044776145277858 predictions [tensor(0.65636316, requires_grad=True), tensor(0.63094863, requires_grad=True), tensor(0.65636316, requires_grad=True), tensor(0.63094863, requires_grad=True)]\n",
            "Iter:    29 | Cost: 1.0681699 | Accuracy: 1.0000000 \n",
            "step 29 [[0.3        0.59235043 0.37104173 0.5       ]\n",
            " [0.59648274 0.5        0.37104173 0.58503765]] 1.068169869758839\n",
            "step 29 params [[0.3        0.59235043 0.37104173 0.5       ]\n",
            " [0.59648274 0.5        0.37104173 0.58503765]] loss 1.068169869758839 predictions [tensor(0.65398087, requires_grad=True), tensor(0.62800367, requires_grad=True), tensor(0.65398087, requires_grad=True), tensor(0.62800367, requires_grad=True)]\n",
            "Iter:    30 | Cost: 0.4652093 | Accuracy: 1.0000000 \n",
            "step 30 [[0.3        0.59644964 0.37423707 0.5       ]\n",
            " [0.60086265 0.5        0.37423707 0.58894355]] 0.4652092629119201\n",
            "step 30 params [[0.3        0.59644964 0.37423707 0.5       ]\n",
            " [0.60086265 0.5        0.37423707 0.58894355]] loss 0.4652092629119201 predictions [tensor(0.65207459, requires_grad=True), tensor(0.62576302, requires_grad=True), tensor(0.65207459, requires_grad=True), tensor(0.62576302, requires_grad=True)]\n",
            "Iter:    31 | Cost: 1.0557672 | Accuracy: 1.0000000 \n",
            "step 31 [[0.3        0.59935456 0.37720464 0.5       ]\n",
            " [0.604181   0.5        0.37720464 0.59224748]] 0.42759632056442304\n",
            "step 31 params [[0.3        0.59935456 0.37720464 0.5       ]\n",
            " [0.604181   0.5        0.37720464 0.59224748]] loss 0.42759632056442304 predictions [tensor(0.65067063, requires_grad=True), tensor(0.62396321, requires_grad=True), tensor(0.65067063, requires_grad=True), tensor(0.62396321, requires_grad=True)]\n",
            "Iter:    32 | Cost: 1.0517400 | Accuracy: 1.0000000 \n",
            "step 32 [[0.3        0.60256508 0.38119418 0.5       ]\n",
            " [0.60816825 0.5        0.38119418 0.59657241]] 0.9780682860578241\n",
            "step 32 params [[0.3        0.60256508 0.38119418 0.5       ]\n",
            " [0.60816825 0.5        0.38119418 0.59657241]] loss 0.9780682860578241 predictions [tensor(0.64904576, requires_grad=True), tensor(0.62172492, requires_grad=True), tensor(0.64904576, requires_grad=True), tensor(0.62172492, requires_grad=True)]\n",
            "Iter:    33 | Cost: 0.9721336 | Accuracy: 1.0000000 \n",
            "step 33 [[0.3        0.60684954 0.3846887  0.5       ]\n",
            " [0.61291285 0.5        0.3846887  0.60096241]] 1.0470994349097267\n",
            "step 33 params [[0.3        0.60684954 0.3846887  0.5       ]\n",
            " [0.61291285 0.5        0.3846887  0.60096241]] loss 1.0470994349097267 predictions [tensor(0.6470646, requires_grad=True), tensor(0.61933744, requires_grad=True), tensor(0.6470646, requires_grad=True), tensor(0.61933744, requires_grad=True)]\n",
            "Iter:    34 | Cost: 0.4353091 | Accuracy: 1.0000000 \n",
            "step 34 [[0.3        0.61205106 0.38769397 0.5       ]\n",
            " [0.61831767 0.5        0.38769397 0.60540076]] 1.0414702359092833\n",
            "step 34 params [[0.3        0.61205106 0.38769397 0.5       ]\n",
            " [0.61831767 0.5        0.38769397 0.60540076]] loss 1.0414702359092833 predictions [tensor(0.644778, requires_grad=True), tensor(0.61683489, requires_grad=True), tensor(0.644778, requires_grad=True), tensor(0.61683489, requires_grad=True)]\n",
            "Iter:    35 | Cost: 0.9592893 | Accuracy: 1.0000000 \n",
            "step 35 [[0.3        0.61803813 0.39021088 0.5       ]\n",
            " [0.62429864 0.5        0.39021088 0.60987054]] 1.0350123200957273\n",
            "step 35 params [[0.3        0.61803813 0.39021088 0.5       ]\n",
            " [0.62429864 0.5        0.39021088 0.60987054]] loss 1.0350123200957273 predictions [tensor(0.64222702, requires_grad=True), tensor(0.61424569, requires_grad=True), tensor(0.64222702, requires_grad=True), tensor(0.61424569, requires_grad=True)]\n",
            "Iter:    36 | Cost: 0.9525546 | Accuracy: 1.0000000 \n",
            "step 36 [[0.3        0.62469968 0.39223668 0.5       ]\n",
            " [0.63078276 0.5        0.39223668 0.61435497]] 1.0278566409103849\n",
            "step 36 params [[0.3        0.62469968 0.39223668 0.5       ]\n",
            " [0.63078276 0.5        0.39223668 0.61435497]] loss 1.0278566409103849 predictions [tensor(0.63944489, requires_grad=True), tensor(0.61159345, requires_grad=True), tensor(0.63944489, requires_grad=True), tensor(0.61159345, requires_grad=True)]\n",
            "Iter:    37 | Cost: 0.4916875 | Accuracy: 1.0000000 \n",
            "step 37 [[0.3        0.62996325 0.39426328 0.5       ]\n",
            " [0.63602367 0.5        0.39426328 0.61821851]] 0.4471548414654349\n",
            "step 37 params [[0.3        0.62996325 0.39426328 0.5       ]\n",
            " [0.63602367 0.5        0.39426328 0.61821851]] loss 0.4471548414654349 predictions [tensor(0.63723371, requires_grad=True), tensor(0.60939176, requires_grad=True), tensor(0.63723371, requires_grad=True), tensor(0.60939176, requires_grad=True)]\n",
            "Iter:    38 | Cost: 1.0139965 | Accuracy: 1.0000000 \n",
            "step 38 [[0.3        0.63444442 0.39531444 0.5       ]\n",
            " [0.64018658 0.5        0.39531444 0.62081132]] 0.49529393518953696\n",
            "step 38 params [[0.3        0.63444442 0.39531444 0.5       ]\n",
            " [0.64018658 0.5        0.39531444 0.62081132]] loss 0.49529393518953696 predictions [tensor(0.63542729, requires_grad=True), tensor(0.60777277, requires_grad=True), tensor(0.63542729, requires_grad=True), tensor(0.60777277, requires_grad=True)]\n",
            "Iter:    39 | Cost: 1.0090293 | Accuracy: 1.0000000 \n",
            "step 39 [[0.3        0.63820918 0.39549517 0.5       ]\n",
            " [0.64336551 0.5        0.39549517 0.62225779]] 0.4979541924916149\n",
            "step 39 params [[0.3        0.63820918 0.39549517 0.5       ]\n",
            " [0.64336551 0.5        0.39549517 0.62225779]] loss 0.4979541924916149 predictions [tensor(0.63398097, requires_grad=True), tensor(0.60667123, requires_grad=True), tensor(0.63398097, requires_grad=True), tensor(0.60667123, requires_grad=True)]\n",
            "Iter:    40 | Cost: 0.4997683 | Accuracy: 1.0000000 \n",
            "step 40 [[0.3        0.64290237 0.3952515  0.5       ]\n",
            " [0.64734348 0.5        0.3952515  0.62394132]] 1.005069964965299\n",
            "step 40 params [[0.3        0.64290237 0.3952515  0.5       ]\n",
            " [0.64734348 0.5        0.3952515  0.62394132]] loss 1.005069964965299 predictions [tensor(0.63216164, requires_grad=True), tensor(0.60536801, requires_grad=True), tensor(0.63216164, requires_grad=True), tensor(0.60536801, requires_grad=True)]\n",
            "Iter:    41 | Cost: 1.0001117 | Accuracy: 1.0000000 \n",
            "step 41 [[0.3        0.64840508 0.39459337 0.5       ]\n",
            " [0.6520302  0.5        0.39459337 0.62583321]] 1.0001116769309575\n",
            "step 41 params [[0.3        0.64840508 0.39459337 0.5       ]\n",
            " [0.6520302  0.5        0.39459337 0.62583321]] loss 1.0001116769309575 predictions [tensor(0.63000846, requires_grad=True), tensor(0.60388973, requires_grad=True), tensor(0.63000846, requires_grad=True), tensor(0.60388973, requires_grad=True)]\n",
            "Iter:    42 | Cost: 0.9942751 | Accuracy: 1.0000000 \n",
            "step 42 [[0.3        0.65259708 0.39426937 0.5       ]\n",
            " [0.65561511 0.5        0.39426937 0.62735176]] 0.46202202536240206\n",
            "step 42 params [[0.3        0.65259708 0.39426937 0.5       ]\n",
            " [0.65561511 0.5        0.39426937 0.62735176]] loss 0.46202202536240206 predictions [tensor(0.62836539, requires_grad=True), tensor(0.60273034, requires_grad=True), tensor(0.62836539, requires_grad=True), tensor(0.60273034, requires_grad=True)]\n",
            "Iter:    43 | Cost: 0.5062854 | Accuracy: 1.0000000 \n",
            "step 43 [[0.3        0.65559588 0.39426767 0.5       ]\n",
            " [0.65819292 0.5        0.39426767 0.62853196]] 0.4646334429914637\n",
            "step 43 params [[0.3        0.65559588 0.39426767 0.5       ]\n",
            " [0.65819292 0.5        0.39426767 0.62853196]] loss 0.4646334429914637 predictions [tensor(0.627192, requires_grad=True), tensor(0.60186083, requires_grad=True), tensor(0.627192, requires_grad=True), tensor(0.60186083, requires_grad=True)]\n",
            "Iter:    44 | Cost: 0.4665026 | Accuracy: 1.0000000 \n",
            "step 44 [[0.3        0.65750961 0.39457378 0.5       ]\n",
            " [0.65985107 0.5        0.39457378 0.62940481]] 0.466502565059358\n",
            "step 44 params [[0.3        0.65750961 0.39457378 0.5       ]\n",
            " [0.65985107 0.5        0.39457378 0.62940481]] loss 0.466502565059358 predictions [tensor(0.62644929, requires_grad=True), tensor(0.60125437, requires_grad=True), tensor(0.62644929, requires_grad=True), tensor(0.60125437, requires_grad=True)]\n",
            "Iter:    45 | Cost: 0.9847015 | Accuracy: 1.0000000 \n",
            "step 45 [[0.3        0.66053695 0.39431873 0.5       ]\n",
            " [0.66246937 0.5        0.39431873 0.63053832]] 0.9847015021993034\n",
            "step 45 params [[0.3        0.66053695 0.39431873 0.5       ]\n",
            " [0.66246937 0.5        0.39431873 0.63053832]] loss 0.9847015021993034 predictions [tensor(0.62525182, requires_grad=True), tensor(0.60041044, requires_grad=True), tensor(0.62525182, requires_grad=True), tensor(0.60041044, requires_grad=True)]\n",
            "Iter:    46 | Cost: 0.4696008 | Accuracy: 1.0000000 \n",
            "step 46 [[0.3        0.66454207 0.39353402 0.5       ]\n",
            " [0.665942   0.5        0.39353402 0.63190511]] 0.9815010000746512\n",
            "step 46 params [[0.3        0.66454207 0.39353402 0.5       ]\n",
            " [0.665942   0.5        0.39353402 0.63190511]] loss 0.9815010000746512 predictions [tensor(0.62364754, requires_grad=True), tensor(0.59935742, requires_grad=True), tensor(0.62364754, requires_grad=True), tensor(0.59935742, requires_grad=True)]\n",
            "Iter:    47 | Cost: 0.9146856 | Accuracy: 1.0000000 \n",
            "step 47 [[0.3        0.66940619 0.39224473 0.5       ]\n",
            " [0.67017495 0.5        0.39224473 0.63347838]] 0.9772291706423565\n",
            "step 47 params [[0.3        0.66940619 0.39224473 0.5       ]\n",
            " [0.67017495 0.5        0.39224473 0.63347838]] loss 0.9772291706423565 predictions [tensor(0.62167709, requires_grad=True), tensor(0.59811988, requires_grad=True), tensor(0.62167709, requires_grad=True), tensor(0.59811988, requires_grad=True)]\n",
            "Iter:    48 | Cost: 0.9116014 | Accuracy: 1.0000000 \n",
            "step 48 [[0.3        0.67301386 0.39144089 0.5       ]\n",
            " [0.67332435 0.5        0.39144089 0.63471512]] 0.4753344700690587\n",
            "step 48 params [[0.3        0.67301386 0.39144089 0.5       ]\n",
            " [0.67332435 0.5        0.39144089 0.63471512]] loss 0.4753344700690587 predictions [tensor(0.62021419, requires_grad=True), tensor(0.59717315, requires_grad=True), tensor(0.62021419, requires_grad=True), tensor(0.59717315, requires_grad=True)]\n",
            "Iter:    49 | Cost: 0.9092485 | Accuracy: 1.0000000 \n",
            "step 49 [[0.3        0.67674695 0.39176455 0.5       ]\n",
            " [0.67707158 0.5        0.39176455 0.63726503]] 0.909248461162876\n",
            "step 49 params [[0.3        0.67674695 0.39176455 0.5       ]\n",
            " [0.67707158 0.5        0.39176455 0.63726503]] loss 0.909248461162876 predictions [tensor(0.61861898, requires_grad=True), tensor(0.59579797, requires_grad=True), tensor(0.61861898, requires_grad=True), tensor(0.59579797, requires_grad=True)]\n",
            "Iter:    50 | Cost: 0.9639564 | Accuracy: 1.0000000 \n",
            "step 50 [[0.3        0.68059348 0.39307039 0.5       ]\n",
            " [0.68135525 0.5        0.39307039 0.64095431]] 0.9058404460167373\n",
            "step 50 params [[0.3        0.68059348 0.39307039 0.5       ]\n",
            " [0.68135525 0.5        0.39307039 0.64095431]] loss 0.9058404460167373 predictions [tensor(0.61691467, requires_grad=True), tensor(0.5940567, requires_grad=True), tensor(0.61691467, requires_grad=True), tensor(0.5940567, requires_grad=True)]\n",
            "Iter:    51 | Cost: 0.9015418 | Accuracy: 1.0000000 \n",
            "step 51 [[0.3        0.68532086 0.39357393 0.5       ]\n",
            " [0.68631021 0.5        0.39357393 0.64459692]] 0.9594975106294343\n",
            "step 51 params [[0.3        0.68532086 0.39357393 0.5       ]\n",
            " [0.68631021 0.5        0.39357393 0.64459692]] loss 0.9594975106294343 predictions [tensor(0.61485781, requires_grad=True), tensor(0.59222087, requires_grad=True), tensor(0.61485781, requires_grad=True), tensor(0.59222087, requires_grad=True)]\n",
            "Iter:    52 | Cost: 0.9541427 | Accuracy: 1.0000000 \n",
            "step 52 [[0.3        0.68878119 0.39448058 0.5       ]\n",
            " [0.69009924 0.5        0.39448058 0.64774058]] 0.4863642344293955\n",
            "step 52 params [[0.3        0.68878119 0.39448058 0.5       ]\n",
            " [0.69009924 0.5        0.39448058 0.64774058]] loss 0.4863642344293955 predictions [tensor(0.61334285, requires_grad=True), tensor(0.59073466, requires_grad=True), tensor(0.61334285, requires_grad=True), tensor(0.59073466, requires_grad=True)]\n",
            "Iter:    53 | Cost: 0.4888312 | Accuracy: 1.0000000 \n",
            "step 53 [[0.3        0.69314856 0.39455452 0.5       ]\n",
            " [0.69460324 0.5        0.39455452 0.65086836]] 0.9502168893358355\n",
            "step 53 params [[0.3        0.69314856 0.39455452 0.5       ]\n",
            " [0.69460324 0.5        0.39455452 0.65086836]] loss 0.9502168893358355 predictions [tensor(0.61145135, requires_grad=True), tensor(0.58913588, requires_grad=True), tensor(0.61145135, requires_grad=True), tensor(0.58913588, requires_grad=True)]\n",
            "Iter:    54 | Cost: 0.8894927 | Accuracy: 1.0000000 \n",
            "step 54 [[0.3        0.69754502 0.39551393 0.5       ]\n",
            " [0.69954935 0.5        0.39551393 0.65506284]] 0.8894927294586289\n",
            "step 54 params [[0.3        0.69754502 0.39551393 0.5       ]\n",
            " [0.69954935 0.5        0.39551393 0.65506284]] loss 0.8894927294586289 predictions [tensor(0.60949941, requires_grad=True), tensor(0.58722775, requires_grad=True), tensor(0.60949941, requires_grad=True), tensor(0.58722775, requires_grad=True)]\n",
            "Iter:    55 | Cost: 0.8848593 | Accuracy: 1.0000000 \n",
            "step 55 [[0.3        0.70196424 0.39723408 0.5       ]\n",
            " [0.70488989 0.5        0.39723408 0.66018213]] 0.88485928655843\n",
            "step 55 params [[0.3        0.70196424 0.39723408 0.5       ]\n",
            " [0.70488989 0.5        0.39723408 0.66018213]] loss 0.88485928655843 predictions [tensor(0.60750532, requires_grad=True), tensor(0.58506183, requires_grad=True), tensor(0.60750532, requires_grad=True), tensor(0.58506183, requires_grad=True)]\n",
            "Iter:    56 | Cost: 0.4983944 | Accuracy: 1.0000000 \n",
            "step 56 [[0.3        0.70568451 0.39821587 0.5       ]\n",
            " [0.70910894 0.5        0.39821587 0.66381759]] 0.5360377429271953\n",
            "step 56 params [[0.3        0.70568451 0.39821587 0.5       ]\n",
            " [0.70910894 0.5        0.39821587 0.66381759]] loss 0.5360377429271953 predictions [tensor(0.60587826, requires_grad=True), tensor(0.58343978, requires_grad=True), tensor(0.60587826, requires_grad=True), tensor(0.58343978, requires_grad=True)]\n",
            "Iter:    57 | Cost: 0.9310954 | Accuracy: 1.0000000 \n",
            "step 57 [[0.3        0.70948164 0.3998868  0.5       ]\n",
            " [0.71378704 0.5        0.3998868  0.66840701]] 0.8757242534764772\n",
            "step 57 params [[0.3        0.70948164 0.3998868  0.5       ]\n",
            " [0.71378704 0.5        0.3998868  0.66840701]] loss 0.8757242534764772 predictions [tensor(0.60418424, requires_grad=True), tensor(0.58154946, requires_grad=True), tensor(0.60418424, requires_grad=True), tensor(0.58154946, requires_grad=True)]\n",
            "Iter:    58 | Cost: 0.5038761 | Accuracy: 1.0000000 \n",
            "step 58 [[0.3        0.71206311 0.40200585 0.5       ]\n",
            " [0.71730629 0.5        0.40200585 0.6724526 ]] 0.5038760878274203\n",
            "step 58 params [[0.3        0.71206311 0.40200585 0.5       ]\n",
            " [0.71730629 0.5        0.40200585 0.6724526 ]] loss 0.5038760878274203 predictions [tensor(0.60303126, requires_grad=True), tensor(0.58000955, requires_grad=True), tensor(0.60303126, requires_grad=True), tensor(0.58000955, requires_grad=True)]\n",
            "Iter:    59 | Cost: 0.5057863 | Accuracy: 1.0000000 \n",
            "step 59 [[0.3        0.71354564 0.40455534 0.5       ]\n",
            " [0.71977443 0.5        0.40455534 0.67600782]] 0.5057862503070278\n",
            "step 59 params [[0.3        0.71354564 0.40455534 0.5       ]\n",
            " [0.71977443 0.5        0.40455534 0.67600782]] loss 0.5057862503070278 predictions [tensor(0.60236811, requires_grad=True), tensor(0.57878259, requires_grad=True), tensor(0.60236811, requires_grad=True), tensor(0.57878259, requires_grad=True)]\n",
            "Iter:    60 | Cost: 0.5068865 | Accuracy: 1.0000000 \n",
            "step 60 [[0.3        0.71614224 0.40587066 0.5       ]\n",
            " [0.72306997 0.5        0.40587066 0.67942529]] 0.9222286055464863\n",
            "step 60 params [[0.3        0.71614224 0.40587066 0.5       ]\n",
            " [0.72306997 0.5        0.40587066 0.67942529]] loss 0.9222286055464863 predictions [tensor(0.60122948, requires_grad=True), tensor(0.57745035, requires_grad=True), tensor(0.60122948, requires_grad=True), tensor(0.57745035, requires_grad=True)]\n",
            "Iter:    61 | Cost: 0.5491328 | Accuracy: 1.0000000 \n",
            "step 61 [[0.3        0.71889415 0.40773653 0.5       ]\n",
            " [0.72689628 0.5        0.40773653 0.68380983]] 0.8614483140015595\n",
            "step 61 params [[0.3        0.71889415 0.40773653 0.5       ]\n",
            " [0.72689628 0.5        0.40773653 0.68380983]] loss 0.8614483140015595 predictions [tensor(0.59999358, requires_grad=True), tensor(0.57584839, requires_grad=True), tensor(0.59999358, requires_grad=True), tensor(0.57584839, requires_grad=True)]\n",
            "Iter:    62 | Cost: 0.5519109 | Accuracy: 1.0000000 \n",
            "step 62 [[0.3        0.72261504 0.40837688 0.5       ]\n",
            " [0.73140071 0.5        0.40837688 0.68796162]] 0.9162746933142506\n",
            "step 62 params [[0.3        0.72261504 0.40837688 0.5       ]\n",
            " [0.73140071 0.5        0.40837688 0.68796162]] loss 0.9162746933142506 predictions [tensor(0.59834125, requires_grad=True), tensor(0.5741884, requires_grad=True), tensor(0.59834125, requires_grad=True), tensor(0.5741884, requires_grad=True)]\n",
            "Iter:    63 | Cost: 0.5135940 | Accuracy: 1.0000000 \n",
            "step 63 [[0.3        0.72637417 0.40956331 0.5       ]\n",
            " [0.7363066  0.5        0.40956331 0.69298588]] 0.8537582774311447\n",
            "step 63 params [[0.3        0.72637417 0.40956331 0.5       ]\n",
            " [0.7363066  0.5        0.40956331 0.69298588]] loss 0.8537582774311447 predictions [tensor(0.59664834, requires_grad=True), tensor(0.57230864, requires_grad=True), tensor(0.59664834, requires_grad=True), tensor(0.57230864, requires_grad=True)]\n",
            "Iter:    64 | Cost: 0.9079465 | Accuracy: 1.0000000 \n",
            "step 64 [[0.3        0.72891588 0.41138671 0.5       ]\n",
            " [0.74002745 0.5        0.41138671 0.69745856]] 0.5164273853171242\n",
            "step 64 params [[0.3        0.72891588 0.41138671 0.5       ]\n",
            " [0.74002745 0.5        0.41138671 0.69745856]] loss 0.5164273853171242 predictions [tensor(0.59551268, requires_grad=True), tensor(0.57076765, requires_grad=True), tensor(0.59551268, requires_grad=True), tensor(0.57076765, requires_grad=True)]\n",
            "Iter:    65 | Cost: 0.5183326 | Accuracy: 1.0000000 \n",
            "step 65 [[0.3        0.73159243 0.41357614 0.5       ]\n",
            " [0.74421833 0.5        0.41357614 0.70275349]] 0.8457568947703011\n",
            "step 65 params [[0.3        0.73159243 0.41357614 0.5       ]\n",
            " [0.74421833 0.5        0.41357614 0.70275349]] loss 0.8457568947703011 predictions [tensor(0.59429793, requires_grad=True), tensor(0.569015, requires_grad=True), tensor(0.59429793, requires_grad=True), tensor(0.569015, requires_grad=True)]\n",
            "Iter:    66 | Cost: 0.8416820 | Accuracy: 1.0000000 \n",
            "step 66 [[0.3        0.73374901 0.41518411 0.5       ]\n",
            " [0.74738626 0.5        0.41518411 0.70654613]] 0.5638484901443899\n",
            "step 66 params [[0.3        0.73374901 0.41518411 0.5       ]\n",
            " [0.74738626 0.5        0.41518411 0.70654613]] loss 0.5638484901443899 predictions [tensor(0.5933637, requires_grad=True), tensor(0.56772884, requires_grad=True), tensor(0.5933637, requires_grad=True), tensor(0.56772884, requires_grad=True)]\n",
            "Iter:    67 | Cost: 0.5661114 | Accuracy: 1.0000000 \n",
            "step 67 [[0.3        0.73483084 0.41747065 0.5       ]\n",
            " [0.74953003 0.5        0.41747065 0.70991648]] 0.5219477450051945\n",
            "step 67 params [[0.3        0.73483084 0.41747065 0.5       ]\n",
            " [0.74953003 0.5        0.41747065 0.70991648]] loss 0.5219477450051945 predictions [tensor(0.59292223, requires_grad=True), tensor(0.56671804, requires_grad=True), tensor(0.59292223, requires_grad=True), tensor(0.56671804, requires_grad=True)]\n",
            "Iter:    68 | Cost: 0.5678934 | Accuracy: 1.0000000 \n",
            "step 68 [[0.3        0.73494349 0.42038747 0.5       ]\n",
            " [0.75074696 0.5        0.42038747 0.7129065 ]] 0.5226920341606585\n",
            "step 68 params [[0.3        0.73494349 0.42038747 0.5       ]\n",
            " [0.75074696 0.5        0.42038747 0.7129065 ]] loss 0.5226920341606585 predictions [tensor(0.59292615, requires_grad=True), tensor(0.5659539, requires_grad=True), tensor(0.59292615, requires_grad=True), tensor(0.5659539, requires_grad=True)]\n",
            "Iter:    69 | Cost: 0.5692427 | Accuracy: 1.0000000 \n",
            "step 69 [[0.3        0.73539764 0.42347488 0.5       ]\n",
            " [0.75266467 0.5        0.42347488 0.71685636]] 0.8346045182377501\n",
            "step 69 params [[0.3        0.73539764 0.42347488 0.5       ]\n",
            " [0.75266467 0.5        0.42347488 0.71685636]] loss 0.8346045182377501 predictions [tensor(0.59274603, requires_grad=True), tensor(0.5649172, requires_grad=True), tensor(0.59274603, requires_grad=True), tensor(0.5649172, requires_grad=True)]\n",
            "Iter:    70 | Cost: 0.5229893 | Accuracy: 1.0000000 \n",
            "step 70 [[0.3        0.73615877 0.42669776 0.5       ]\n",
            " [0.75521004 0.5        0.42669776 0.72164813]] 0.8322189232067577\n",
            "step 70 params [[0.3        0.73615877 0.42669776 0.5       ]\n",
            " [0.75521004 0.5        0.42669776 0.72164813]] loss 0.8322189232067577 predictions [tensor(0.59240658, requires_grad=True), tensor(0.56364715, requires_grad=True), tensor(0.59240658, requires_grad=True), tensor(0.56364715, requires_grad=True)]\n",
            "Iter:    71 | Cost: 0.5235621 | Accuracy: 1.0000000 \n",
            "step 71 [[0.3        0.73719418 0.43001755 0.5       ]\n",
            " [0.75831625 0.5        0.43001755 0.72717677]] 0.8293040704678951\n",
            "step 71 params [[0.3        0.73719418 0.43001755 0.5       ]\n",
            " [0.75831625 0.5        0.43001755 0.72717677]] loss 0.8293040704678951 predictions [tensor(0.59193013, requires_grad=True), tensor(0.5621796, requires_grad=True), tensor(0.59193013, requires_grad=True), tensor(0.5621796, requires_grad=True)]\n",
            "Iter:    72 | Cost: 0.8259465 | Accuracy: 1.0000000 \n",
            "step 72 [[0.3        0.73847307 0.4333931  0.5       ]\n",
            " [0.76192238 0.5        0.4333931  0.73334876]] 0.8259464890881831\n",
            "step 72 params [[0.3        0.73847307 0.4333931  0.5       ]\n",
            " [0.76192238 0.5        0.4333931  0.73334876]] loss 0.8259464890881831 predictions [tensor(0.5913365, requires_grad=True), tensor(0.56054704, requires_grad=True), tensor(0.5913365, requires_grad=True), tensor(0.56054704, requires_grad=True)]\n",
            "Iter:    73 | Cost: 0.5788421 | Accuracy: 1.0000000 \n",
            "step 73 [[0.3        0.74086951 0.43498772 0.5       ]\n",
            " [0.76618951 0.5        0.43498772 0.73902461]] 0.8948632113454448\n",
            "step 73 params [[0.3        0.74086951 0.43498772 0.5       ]\n",
            " [0.76618951 0.5        0.43498772 0.73902461]] loss 0.8948632113454448 predictions [tensor(0.59023207, requires_grad=True), tensor(0.55889458, requires_grad=True), tensor(0.59023207, requires_grad=True), tensor(0.55889458, requires_grad=True)]\n",
            "Iter:    74 | Cost: 0.8921643 | Accuracy: 1.0000000 \n",
            "step 74 [[0.3        0.74279131 0.4362165  0.5       ]\n",
            " [0.76943091 0.5        0.4362165  0.74318299]] 0.5817944097128707\n",
            "step 74 params [[0.3        0.74279131 0.4362165  0.5       ]\n",
            " [0.76943091 0.5        0.4362165  0.74318299]] loss 0.5817944097128707 predictions [tensor(0.58938768, requires_grad=True), tensor(0.55766701, requires_grad=True), tensor(0.58938768, requires_grad=True), tensor(0.55766701, requires_grad=True)]\n",
            "Iter:    75 | Cost: 0.5286711 | Accuracy: 1.0000000 \n",
            "step 75 [[0.3        0.74575222 0.4358418  0.5       ]\n",
            " [0.77336152 0.5        0.4358418  0.74701263]] 0.8901057599706381\n",
            "step 75 params [[0.3        0.74575222 0.4358418  0.5       ]\n",
            " [0.77336152 0.5        0.4358418  0.74701263]] loss 0.8901057599706381 predictions [tensor(0.58804158, requires_grad=True), tensor(0.55636904, requires_grad=True), tensor(0.58804158, requires_grad=True), tensor(0.55636904, requires_grad=True)]\n",
            "Iter:    76 | Cost: 0.5309576 | Accuracy: 1.0000000 \n",
            "step 76 [[0.3        0.74755648 0.43654777 0.5       ]\n",
            " [0.77620501 0.5        0.43654777 0.75046013]] 0.5309576234157145\n",
            "step 76 params [[0.3        0.74755648 0.43654777 0.5       ]\n",
            " [0.77620501 0.5        0.43654777 0.75046013]] loss 0.5309576234157145 predictions [tensor(0.58724899, requires_grad=True), tensor(0.55533498, requires_grad=True), tensor(0.58724899, requires_grad=True), tensor(0.55533498, requires_grad=True)]\n",
            "Iter:    77 | Cost: 0.5323064 | Accuracy: 1.0000000 \n",
            "step 77 [[0.3        0.7503984  0.43568476 0.5       ]\n",
            " [0.77977265 0.5        0.43568476 0.75363075]] 0.8849107601115023\n",
            "step 77 params [[0.3        0.7503984  0.43568476 0.5       ]\n",
            " [0.77977265 0.5        0.43568476 0.75363075]] loss 0.8849107601115023 predictions [tensor(0.58594402, requires_grad=True), tensor(0.55420788, requires_grad=True), tensor(0.58594402, requires_grad=True), tensor(0.55420788, requires_grad=True)]\n",
            "Iter:    78 | Cost: 0.5345310 | Accuracy: 1.0000000 \n",
            "step 78 [[0.3        0.75416028 0.43342644 0.5       ]\n",
            " [0.7839884  0.5        0.43342644 0.75654372]] 0.8817540912329753\n",
            "step 78 params [[0.3        0.75416028 0.43342644 0.5       ]\n",
            " [0.7839884  0.5        0.43342644 0.75654372]] loss 0.8817540912329753 predictions [tensor(0.58417638, requires_grad=True), tensor(0.55299139, requires_grad=True), tensor(0.58417638, requires_grad=True), tensor(0.55299139, requires_grad=True)]\n",
            "Iter:    79 | Cost: 0.8774941 | Accuracy: 1.0000000 \n",
            "step 79 [[0.3        0.75786695 0.43149718 0.5       ]\n",
            " [0.78857391 0.5        0.43149718 0.76037704]] 0.8051774338579346\n",
            "step 79 params [[0.3        0.75786695 0.43149718 0.5       ]\n",
            " [0.78857391 0.5        0.43149718 0.76037704]] loss 0.8051774338579346 predictions [tensor(0.58238826, requires_grad=True), tensor(0.55157971, requires_grad=True), tensor(0.58238826, requires_grad=True), tensor(0.55157971, requires_grad=True)]\n",
            "Iter:    80 | Cost: 0.5406179 | Accuracy: 1.0000000 \n",
            "step 80 [[0.3        0.76033619 0.43086262 0.5       ]\n",
            " [0.7919968  0.5        0.43086262 0.76384407]] 0.5406179422710996\n",
            "step 80 params [[0.3        0.76033619 0.43086262 0.5       ]\n",
            " [0.7919968  0.5        0.43086262 0.76384407]] loss 0.5406179422710996 predictions [tensor(0.58121087, requires_grad=True), tensor(0.55044482, requires_grad=True), tensor(0.58121087, requires_grad=True), tensor(0.55044482, requires_grad=True)]\n",
            "Iter:    81 | Cost: 0.7994967 | Accuracy: 1.0000000 \n",
            "step 81 [[0.3        0.76234596 0.43023776 0.5       ]\n",
            " [0.79445578 0.5        0.43023776 0.7659611 ]] 0.5970285583643278\n",
            "step 81 params [[0.3        0.76234596 0.43023776 0.5       ]\n",
            " [0.79445578 0.5        0.43023776 0.7659611 ]] loss 0.5970285583643278 predictions [tensor(0.58030017, requires_grad=True), tensor(0.54967449, requires_grad=True), tensor(0.58030017, requires_grad=True), tensor(0.54967449, requires_grad=True)]\n",
            "Iter:    82 | Cost: 0.5984290 | Accuracy: 1.0000000 \n",
            "step 82 [[0.3        0.76536214 0.4281304  0.5       ]\n",
            " [0.79767403 0.5        0.4281304  0.76789297]] 0.8682155123366534\n",
            "step 82 params [[0.3        0.76536214 0.4281304  0.5       ]\n",
            " [0.79767403 0.5        0.4281304  0.76789297]] loss 0.8682155123366534 predictions [tensor(0.57886991, requires_grad=True), tensor(0.54877389, requires_grad=True), tensor(0.57886991, requires_grad=True), tensor(0.54877389, requires_grad=True)]\n",
            "Iter:    83 | Cost: 0.8648135 | Accuracy: 1.0000000 \n",
            "step 83 [[0.3        0.76719831 0.42737011 0.5       ]\n",
            " [0.79984906 0.5        0.42737011 0.76964364]] 0.5466775137470777\n",
            "step 83 params [[0.3        0.76719831 0.42737011 0.5       ]\n",
            " [0.79984906 0.5        0.42737011 0.76964364]] loss 0.5466775137470777 predictions [tensor(0.57802635, requires_grad=True), tensor(0.54810692, requires_grad=True), tensor(0.57802635, requires_grad=True), tensor(0.54810692, requires_grad=True)]\n",
            "Iter:    84 | Cost: 0.5481358 | Accuracy: 1.0000000 \n",
            "step 84 [[0.3        0.76913852 0.4266849  0.5       ]\n",
            " [0.8025979  0.5        0.4266849  0.77245078]] 0.7943096756450108\n",
            "step 84 params [[0.3        0.76913852 0.4266849  0.5       ]\n",
            " [0.8025979  0.5        0.4266849  0.77245078]] loss 0.7943096756450108 predictions [tensor(0.57707007, requires_grad=True), tensor(0.54719434, requires_grad=True), tensor(0.57707007, requires_grad=True), tensor(0.54719434, requires_grad=True)]\n",
            "Iter:    85 | Cost: 0.5497916 | Accuracy: 1.0000000 \n",
            "step 85 [[0.3        0.77117051 0.42604623 0.5       ]\n",
            " [0.80586563 0.5        0.42604623 0.77619633]] 0.7922922451500121\n",
            "step 85 params [[0.3        0.77117051 0.42604623 0.5       ]\n",
            " [0.80586563 0.5        0.42604623 0.77619633]] loss 0.7922922451500121 predictions [tensor(0.5760117, requires_grad=True), tensor(0.54606302, requires_grad=True), tensor(0.5760117, requires_grad=True), tensor(0.54606302, requires_grad=True)]\n",
            "Iter:    86 | Cost: 0.6050209 | Accuracy: 1.0000000 \n",
            "step 86 [[0.3        0.77328177 0.42542238 0.5       ]\n",
            " [0.80960191 0.5        0.42542238 0.78077452]] 0.7897968974778024\n",
            "step 86 params [[0.3        0.77328177 0.42542238 0.5       ]\n",
            " [0.80960191 0.5        0.42542238 0.78077452]] loss 0.7897968974778024 predictions [tensor(0.57486073, requires_grad=True), tensor(0.54473732, requires_grad=True), tensor(0.57486073, requires_grad=True), tensor(0.54473732, requires_grad=True)]\n",
            "Iter:    87 | Cost: 0.8553385 | Accuracy: 1.0000000 \n",
            "step 87 [[0.3        0.77545959 0.42477934 0.5       ]\n",
            " [0.81376073 0.5        0.42477934 0.78609065]] 0.7868807008923013\n",
            "step 87 params [[0.3        0.77545959 0.42477934 0.5       ]\n",
            " [0.81376073 0.5        0.42477934 0.78609065]] loss 0.7868807008923013 predictions [tensor(0.5736255, requires_grad=True), tensor(0.54323908, requires_grad=True), tensor(0.5736255, requires_grad=True), tensor(0.54323908, requires_grad=True)]\n",
            "Iter:    88 | Cost: 0.5557785 | Accuracy: 1.0000000 \n",
            "step 88 [[0.3        0.77863238 0.42255096 0.5       ]\n",
            " [0.81850356 0.5        0.42255096 0.79089619]] 0.8524372037202042\n",
            "step 88 params [[0.3        0.77863238 0.42255096 0.5       ]\n",
            " [0.81850356 0.5        0.42255096 0.79089619]] loss 0.8524372037202042 predictions [tensor(0.57188357, requires_grad=True), tensor(0.54166926, requires_grad=True), tensor(0.57188357, requires_grad=True), tensor(0.54166926, requires_grad=True)]\n",
            "Iter:    89 | Cost: 0.5588199 | Accuracy: 1.0000000 \n",
            "step 89 [[0.3        0.78268561 0.41892675 0.5       ]\n",
            " [0.82376747 0.5        0.41892675 0.79523184]] 0.848360091247953\n",
            "step 89 params [[0.3        0.78268561 0.41892675 0.5       ]\n",
            " [0.82376747 0.5        0.41892675 0.79523184]] loss 0.848360091247953 predictions [tensor(0.56968686, requires_grad=True), tensor(0.54002827, requires_grad=True), tensor(0.56968686, requires_grad=True), tensor(0.54002827, requires_grad=True)]\n",
            "Iter:    90 | Cost: 0.6161338 | Accuracy: 1.0000000 \n",
            "step 90 [[0.3        0.78542928 0.41692643 0.5       ]\n",
            " [0.82777103 0.5        0.41692643 0.79919147]] 0.56266843130107\n",
            "step 90 params [[0.3        0.78542928 0.41692643 0.5       ]\n",
            " [0.82777103 0.5        0.41692643 0.79919147]] loss 0.56266843130107 predictions [tensor(0.56818763, requires_grad=True), tensor(0.53870236, requires_grad=True), tensor(0.56818763, requires_grad=True), tensor(0.53870236, requires_grad=True)]\n",
            "Iter:    91 | Cost: 0.8397641 | Accuracy: 1.0000000 \n",
            "step 91 [[0.3        0.78699031 0.41639036 0.5       ]\n",
            " [0.83063172 0.5        0.41639036 0.80281406]] 0.5653035862875575\n",
            "step 91 params [[0.3        0.78699031 0.41639036 0.5       ]\n",
            " [0.83063172 0.5        0.41639036 0.80281406]] loss 0.5653035862875575 predictions [tensor(0.56732301, requires_grad=True), tensor(0.53766921, requires_grad=True), tensor(0.56732301, requires_grad=True), tensor(0.53766921, requires_grad=True)]\n",
            "Iter:    92 | Cost: 0.8377638 | Accuracy: 1.0000000 \n",
            "step 92 [[0.3        0.78958031 0.41427477 0.5       ]\n",
            " [0.83419665 0.5        0.41427477 0.80605857]] 0.8377638031527926\n",
            "step 92 params [[0.3        0.78958031 0.41427477 0.5       ]\n",
            " [0.83419665 0.5        0.41427477 0.80605857]] loss 0.8377638031527926 predictions [tensor(0.56591425, requires_grad=True), tensor(0.53651365, requires_grad=True), tensor(0.56591425, requires_grad=True), tensor(0.53651365, requires_grad=True)]\n",
            "Iter:    93 | Cost: 0.5693127 | Accuracy: 1.0000000 \n",
            "step 93 [[0.3        0.79308461 0.41077278 0.5       ]\n",
            " [0.8383925  0.5        0.41077278 0.80895465]] 0.8345131762313364\n",
            "step 93 params [[0.3        0.79308461 0.41077278 0.5       ]\n",
            " [0.8383925  0.5        0.41077278 0.80895465]] loss 0.8345131762313364 predictions [tensor(0.5640194, requires_grad=True), tensor(0.53524433, requires_grad=True), tensor(0.5640194, requires_grad=True), tensor(0.53524433, requires_grad=True)]\n",
            "Iter:    94 | Cost: 0.5726666 | Accuracy: 1.0000000 \n",
            "step 94 [[0.3        0.79533249 0.40888673 0.5       ]\n",
            " [0.8414184  0.5        0.40888673 0.81162418]] 0.5726666260631433\n",
            "step 94 params [[0.3        0.79533249 0.40888673 0.5       ]\n",
            " [0.8414184  0.5        0.40888673 0.81162418]] loss 0.5726666260631433 predictions [tensor(0.56280025, requires_grad=True), tensor(0.53426485, requires_grad=True), tensor(0.56280025, requires_grad=True), tensor(0.53426485, requires_grad=True)]\n",
            "Iter:    95 | Cost: 0.8273651 | Accuracy: 1.0000000 \n",
            "step 95 [[0.3        0.79757617 0.4068964  0.5       ]\n",
            " [0.84493742 0.5        0.4068964  0.81527953]] 0.7641381555254311\n",
            "step 95 params [[0.3        0.79757617 0.4068964  0.5       ]\n",
            " [0.84493742 0.5        0.4068964  0.81527953]] loss 0.7641381555254311 predictions [tensor(0.56148623, requires_grad=True), tensor(0.53305942, requires_grad=True), tensor(0.56148623, requires_grad=True), tensor(0.53305942, requires_grad=True)]\n",
            "Iter:    96 | Cost: 0.5771680 | Accuracy: 1.0000000 \n",
            "step 96 [[0.3        0.80076251 0.40350945 0.5       ]\n",
            " [0.84908937 0.5        0.40350945 0.81853309]] 0.8243640574753519\n",
            "step 96 params [[0.3        0.80076251 0.40350945 0.5       ]\n",
            " [0.84908937 0.5        0.40350945 0.81853309]] loss 0.8243640574753519 predictions [tensor(0.55967614, requires_grad=True), tensor(0.53174126, requires_grad=True), tensor(0.55967614, requires_grad=True), tensor(0.53174126, requires_grad=True)]\n",
            "Iter:    97 | Cost: 0.7587343 | Accuracy: 1.0000000 \n",
            "step 97 [[0.3        0.80384413 0.40011839 0.5       ]\n",
            " [0.85362675 0.5        0.40011839 0.82271409]] 0.758734273924844\n",
            "step 97 params [[0.3        0.80384413 0.40011839 0.5       ]\n",
            " [0.85362675 0.5        0.40011839 0.82271409]] loss 0.758734273924844 predictions [tensor(0.55782359, requires_grad=True), tensor(0.53022255, requires_grad=True), tensor(0.55782359, requires_grad=True), tensor(0.53022255, requires_grad=True)]\n",
            "Iter:    98 | Cost: 0.5837125 | Accuracy: 1.0000000 \n",
            "step 98 [[0.3        0.80777603 0.39549169 0.5       ]\n",
            " [0.85869155 0.5        0.39549169 0.82643337]] 0.8160463555123018\n",
            "step 98 params [[0.3        0.80777603 0.39549169 0.5       ]\n",
            " [0.85869155 0.5        0.39549169 0.82643337]] loss 0.8160463555123018 predictions [tensor(0.55553151, requires_grad=True), tensor(0.52861592, requires_grad=True), tensor(0.55553151, requires_grad=True), tensor(0.52861592, requires_grad=True)]\n",
            "Iter:    99 | Cost: 0.7520821 | Accuracy: 1.0000000 \n",
            "step 99 [[0.3        0.8124619  0.38978669 0.5       ]\n",
            " [0.86422814 0.5        0.38978669 0.8297268 ]] 0.8108761107812491\n",
            "step 99 params [[0.3        0.8124619  0.38978669 0.5       ]\n",
            " [0.86422814 0.5        0.38978669 0.8297268 ]] loss 0.8108761107812491 predictions [tensor(0.55284917, requires_grad=True), tensor(0.52692896, requires_grad=True), tensor(0.55284917, requires_grad=True), tensor(0.52692896, requires_grad=True)]\n",
            "Iter:   100 | Cost: 0.6406895 | Accuracy: 1.0000000 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'state_preparation(x)\\n\\nlosses = []\\nfor i in range(400):\\n  params, loss = optimizer.step_and_cost(circuit, params)\\n  losses.append(loss)\\n  print(loss)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from pennylane import numpy as np\n",
        "\n",
        "num_wires = 4\n",
        "num_layers = 2\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_wires)\n",
        "\n",
        "coeffs = [1]\n",
        "obs = [qml.PauliZ(0) @ qml.PauliZ(1)]\n",
        "H = qml.Hamiltonian(coeffs, obs)\n",
        "\n",
        "#START HERE\n",
        "'''\n",
        "@qml.qnode(dev, interface='autograd')\n",
        "def circuit(params, x=x):\n",
        "  qml.RX(params[0], wires=0)\n",
        "  qml.RZ(params[1], wires=0)\n",
        "  for i in range(1, num_wires):\n",
        "    qml.CNOT([i-1, i])\n",
        "    qml.RX(params[0], wires=i)\n",
        "    qml.RZ(params[1], wires=i)\n",
        "  return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def circuit_0_1(params):\n",
        "  print('check i', circuit(params))\n",
        "  return (circuit(params) + 1)/2\n",
        "'''\n",
        "\n",
        "@qml.qnode(dev, interface='autograd')\n",
        "def circuit(params, x):\n",
        "  x /= np.linalg.norm(x)\n",
        "  #qml.AmplitudeEmbedding(x, wires=list(range(num_wires)))\n",
        "  qml.AngleEmbedding(features=x, wires=range(num_wires), rotation='Y')\n",
        "  qml.BasicEntanglerLayers(weights=params, wires=range(num_wires))\n",
        "\n",
        "  return qml.expval(H)\n",
        "\n",
        "  #print('state', qml.state())\n",
        "  ##print('full_circuit_1', circuit_0_1(params))\n",
        "  #return circuit_0_1(params)\n",
        "\n",
        "#def binary_cost(params):\n",
        "#  return circuit_0_1\n",
        "\n",
        "def full_circuit(params, x):\n",
        "  ###print('circuit result', circuit(params, x))\n",
        "  return (np.array(circuit(params, x)).mean() + 1)/2\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    ##print(labels, predictions)\n",
        "    for true, pred in zip(labels, predictions):\n",
        "        ##print(true, pred)\n",
        "        loss = loss + (true - pred) ** 2\n",
        "\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "def cross_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for true, pred in zip(labels, predictions):\n",
        "      #print(true*np.log(pred + 1))\n",
        "      loss = loss + true*np.log(pred) + (1-true)*np.log(1 - pred)\n",
        "    loss = - loss/len(labels)\n",
        "    return loss\n",
        "\n",
        "def accuracy(labels, predictions):\n",
        "    #loss = (labels - predictions).sum()\n",
        "    loss1 = 0\n",
        "    loss2 = 0\n",
        "    ##print('accuracy', labels, predictions)\n",
        "    for true, pred in zip(labels, predictions):\n",
        "        if true - pred < 0.5:\n",
        "            loss1 = loss1 + 1\n",
        "        if true - pred > 0.5:\n",
        "            loss2 = loss2 + 1\n",
        "    acc1 = loss1 / len(labels)\n",
        "    acc2 = loss2 / len(labels)\n",
        "    return max(acc1, acc2)\n",
        "\n",
        "def cost(params, X_batch, y_batch):\n",
        "    #predictions = full_circuit(params, X_batch)\n",
        "    ##print('X_batch.shape',X_batch.shape)\n",
        "    data_indices = [np.random.randint(0, len(X)) for _ in range(1)]\n",
        "    predictions = [full_circuit(params, X_batch[index]) for index in data_indices]\n",
        "    ##print('len(predictions)',len(predictions))\n",
        "    #predictions = full_circuit(params, X_batch.flatten())\n",
        "    ##print('Cost',y_batch, predictions)\n",
        "    return cross_loss(y_batch[data_indices], predictions)\n",
        "\n",
        "'''\n",
        "def circuit_probs(params):\n",
        "  qml.RX(params[0], wires=0)\n",
        "  qml.RZ(params[1], wires=0)\n",
        "  return qml.probs(wires=0)\n",
        "\n",
        "def cost_probs(params):\n",
        "  return circuit_probs - data'''\n",
        "\n",
        "optimizer = qml.AdamOptimizer(stepsize=0.01)\n",
        "params = np.array([[0.3, 0.5, 0.3, 0.5], [0.5, 0.5, 0.3, 0.5]], requires_grad=True)\n",
        "\n",
        "#X = np.array([[1., 1., 0., 0.], [0., 0., 1., 1.], [1., 0., 1., 0.], [0., 1., 0., 1.]], requires_grad=True)\n",
        "#y = np.array([0, 0, 1, 1], requires_grad=True)\n",
        "\n",
        "losses = []\n",
        "\n",
        "for it in range(100):\n",
        "  #data_index = np.random.randint(0, len(X))\n",
        "  #X_batch = X[data_index]\n",
        "  #y_batch = y[data_index]\n",
        "\n",
        "  X_batch = X\n",
        "  y_batch = y\n",
        "  params, loss = optimizer.step_and_cost(cost, params, X_batch=X_batch, y_batch=y_batch)\n",
        "  print('step', it, params, loss)\n",
        "  losses.append(loss)\n",
        "\n",
        "  predictions = [full_circuit(params, x) for x in X]\n",
        "  print('step', it, 'params', params, 'loss', loss, 'predictions', predictions)\n",
        "  #predictions = full_circuit(params, X.flatten())\n",
        "  acc = accuracy(y, predictions)\n",
        "\n",
        "  print(\n",
        "      \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "          it + 1, cost(params, X, y), acc\n",
        "      )\n",
        "  )\n",
        "\n",
        "'''state_preparation(x)\n",
        "\n",
        "losses = []\n",
        "for i in range(400):\n",
        "  params, loss = optimizer.step_and_cost(circuit, params)\n",
        "  losses.append(loss)\n",
        "  print(loss)'''\n",
        "\n",
        "\n",
        "#END HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses, label='Loss function')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "32f9b9aa-2088-4e48-aaa6-9d754ae93b3c",
        "id": "girxNajPwxNF"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78d6193080a0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "725XXTvzH1TK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "870a4452-767c-4e41-8905-189f28dcdc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 [[0.3        0.49000001 0.29000001 0.5       ]\n",
            " [0.49       0.5        0.29000001 0.49      ]] 0.38399258872749886\n",
            "step 0 params [[0.3        0.49000001 0.29000001 0.5       ]\n",
            " [0.49       0.5        0.29000001 0.49      ]] loss 0.38399258872749886 predictions [tensor(0.70546527, requires_grad=True), tensor(0.68764914, requires_grad=True), tensor(0.70546527, requires_grad=True), tensor(0.68764914, requires_grad=True)]\n",
            "Iter:     1 | Cost: 1.1636282 | Accuracy: 1.0000000 \n",
            "step 1 [[0.3        0.47999957 0.28000087 0.5       ]\n",
            " [0.48000094 0.5        0.28000087 0.48000094]] 0.3744765445158933\n",
            "step 1 params [[0.3        0.47999957 0.28000087 0.5       ]\n",
            " [0.48000094 0.5        0.28000087 0.48000094]] loss 0.3744765445158933 predictions [tensor(0.71092773, requires_grad=True), tensor(0.69419919, requires_grad=True), tensor(0.71092773, requires_grad=True), tensor(0.69419919, requires_grad=True)]\n",
            "Iter:     2 | Cost: 0.3411845 | Accuracy: 1.0000000 \n",
            "step 2 [[0.3        0.4699988  0.27000406 0.5       ]\n",
            " [0.47000386 0.5        0.27000406 0.47000386]] 0.36499634184488255\n",
            "step 2 params [[0.3        0.4699988  0.27000406 0.5       ]\n",
            " [0.47000386 0.5        0.27000406 0.47000386]] loss 0.36499634184488255 predictions [tensor(0.71643997, requires_grad=True), tensor(0.70077522, requires_grad=True), tensor(0.71643997, requires_grad=True), tensor(0.70077522, requires_grad=True)]\n",
            "Iter:     3 | Cost: 1.2065602 | Accuracy: 1.0000000 \n",
            "step 3 [[0.3        0.46025726 0.260876   0.5       ]\n",
            " [0.46000331 0.5        0.260876   0.46060291]] 0.33346081351504936\n",
            "step 3 params [[0.3        0.46025726 0.260876   0.5       ]\n",
            " [0.46000331 0.5        0.260876   0.46060291]] loss 0.33346081351504936 predictions [tensor(0.7218346, requires_grad=True), tensor(0.7070788, requires_grad=True), tensor(0.7218346, requires_grad=True), tensor(0.7070788, requires_grad=True)]\n",
            "Iter:     4 | Cost: 0.3259593 | Accuracy: 1.0000000 \n",
            "step 4 [[0.3        0.45061614 0.2514856  0.5       ]\n",
            " [0.45001155 0.5        0.2514856  0.45101497]] 0.3466131691259224\n",
            "step 4 params [[0.3        0.45061614 0.2514856  0.5       ]\n",
            " [0.45001155 0.5        0.2514856  0.45101497]] loss 0.3466131691259224 predictions [tensor(0.72726594, requires_grad=True), tensor(0.7134568, requires_grad=True), tensor(0.72726594, requires_grad=True), tensor(0.7134568, requires_grad=True)]\n",
            "Iter:     5 | Cost: 1.2992581 | Accuracy: 1.0000000 \n",
            "step 5 [[0.3        0.45120662 0.2463111  0.5       ]\n",
            " [0.44843885 0.5        0.2463111  0.4466259 ]] 1.2992581076106202\n",
            "step 5 params [[0.3        0.45120662 0.2463111  0.5       ]\n",
            " [0.44843885 0.5        0.2463111  0.4466259 ]] loss 1.2992581076106202 predictions [tensor(0.72818865, requires_grad=True), tensor(0.71542047, requires_grad=True), tensor(0.72818865, requires_grad=True), tensor(0.71542047, requires_grad=True)]\n",
            "Iter:     6 | Cost: 0.3348848 | Accuracy: 1.0000000 \n",
            "step 6 [[0.3        0.45086659 0.24015987 0.5       ]\n",
            " [0.44574652 0.5        0.24015987 0.44116348]] 0.3348848438309738\n",
            "step 6 params [[0.3        0.45086659 0.24015987 0.5       ]\n",
            " [0.44574652 0.5        0.24015987 0.44116348]] loss 0.3348848438309738 predictions [tensor(0.72968853, requires_grad=True), tensor(0.71805777, requires_grad=True), tensor(0.72968853, requires_grad=True), tensor(0.71805777, requires_grad=True)]\n",
            "Iter:     7 | Cost: 1.2660531 | Accuracy: 1.0000000 \n",
            "step 7 [[0.3        0.44974244 0.2333099  0.5       ]\n",
            " [0.44216053 0.5        0.2333099  0.43491012]] 0.3312052550543617\n",
            "step 7 params [[0.3        0.44974244 0.2333099  0.5       ]\n",
            " [0.44216053 0.5        0.2333099  0.43491012]] loss 0.3312052550543617 predictions [tensor(0.73165082, requires_grad=True), tensor(0.72120523, requires_grad=True), tensor(0.73165082, requires_grad=True), tensor(0.72120523, requires_grad=True)]\n",
            "Iter:     8 | Cost: 0.3268315 | Accuracy: 1.0000000 \n",
            "step 8 [[0.3        0.45077747 0.23215451 0.5       ]\n",
            " [0.44224296 0.5        0.23215451 0.43408577]] 1.2772793490725443\n",
            "step 8 params [[0.3        0.45077747 0.23215451 0.5       ]\n",
            " [0.44224296 0.5        0.23215451 0.43408577]] loss 1.2772793490725443 predictions [tensor(0.73156712, requires_grad=True), tensor(0.72142522, requires_grad=True), tensor(0.73156712, requires_grad=True), tensor(0.72142522, requires_grad=True)]\n",
            "Iter:     9 | Cost: 1.3151544 | Accuracy: 1.0000000 \n",
            "step 9 [[0.3        0.45094981 0.2299401  0.5       ]\n",
            " [0.44129639 0.5        0.2299401  0.43216221]] 0.32652655606184683\n",
            "step 9 params [[0.3        0.45094981 0.2299401  0.5       ]\n",
            " [0.44129639 0.5        0.2299401  0.43216221]] loss 0.32652655606184683 predictions [tensor(0.73203825, requires_grad=True), tensor(0.72231983, requires_grad=True), tensor(0.73203825, requires_grad=True), tensor(0.72231983, requires_grad=True)]\n",
            "Iter:    10 | Cost: 0.3252873 | Accuracy: 1.0000000 \n",
            "step 10 [[0.3        0.45405964 0.22920502 0.5       ]\n",
            " [0.44302176 0.5        0.22920502 0.43200839]] 1.3169110317785198\n",
            "step 10 params [[0.3        0.45405964 0.22920502 0.5       ]\n",
            " [0.44302176 0.5        0.22920502 0.43200839]] loss 1.3169110317785198 predictions [tensor(0.73109657, requires_grad=True), tensor(0.72179614, requires_grad=True), tensor(0.73109657, requires_grad=True), tensor(0.72179614, requires_grad=True)]\n",
            "Iter:    11 | Cost: 0.3132097 | Accuracy: 1.0000000 \n",
            "step 11 [[0.3        0.45626663 0.22743499 0.5       ]\n",
            " [0.44369517 0.5        0.22743499 0.43075961]] 0.3260125319036725\n",
            "step 11 params [[0.3        0.45626663 0.22743499 0.5       ]\n",
            " [0.44369517 0.5        0.22743499 0.43075961]] loss 0.3260125319036725 predictions [tensor(0.73071777, requires_grad=True), tensor(0.72194855, requires_grad=True), tensor(0.73071777, requires_grad=True), tensor(0.72194855, requires_grad=True)]\n",
            "Iter:    12 | Cost: 1.3119953 | Accuracy: 1.0000000 \n",
            "step 12 [[0.3        0.45960013 0.22855237 0.5       ]\n",
            " [0.44625986 0.5        0.22855237 0.4322684 ]] 1.2799491211934944\n",
            "step 12 params [[0.3        0.45960013 0.22855237 0.5       ]\n",
            " [0.44625986 0.5        0.22855237 0.4322684 ]] loss 1.2799491211934944 predictions [tensor(0.72928409, requires_grad=True), tensor(0.72061664, requires_grad=True), tensor(0.72928409, requires_grad=True), tensor(0.72061664, requires_grad=True)]\n",
            "Iter:    13 | Cost: 1.3066853 | Accuracy: 1.0000000 \n",
            "step 13 [[0.3        0.46386297 0.23163681 0.5       ]\n",
            " [0.45024891 0.5        0.23163681 0.43566537]] 1.2751703824951732\n",
            "step 13 params [[0.3        0.46386297 0.23163681 0.5       ]\n",
            " [0.45024891 0.5        0.23163681 0.43566537]] loss 1.2751703824951732 predictions [tensor(0.72707031, requires_grad=True), tensor(0.71822771, requires_grad=True), tensor(0.72707031, requires_grad=True), tensor(0.71822771, requires_grad=True)]\n",
            "Iter:    14 | Cost: 0.3187321 | Accuracy: 1.0000000 \n",
            "step 14 [[0.3        0.46889522 0.23616016 0.5       ]\n",
            " [0.45534241 0.5        0.23616016 0.44044442]] 1.266656014388765\n",
            "step 14 params [[0.3        0.46889522 0.23616016 0.5       ]\n",
            " [0.45534241 0.5        0.23616016 0.44044442]] loss 1.266656014388765 predictions [tensor(0.72425721, requires_grad=True), tensor(0.71504145, requires_grad=True), tensor(0.72425721, requires_grad=True), tensor(0.71504145, requires_grad=True)]\n",
            "Iter:    15 | Cost: 0.3226087 | Accuracy: 1.0000000 \n",
            "step 15 [[0.3        0.47456633 0.24178126 0.5       ]\n",
            " [0.46130996 0.5        0.24178126 0.44627643]] 1.2554115443443568\n",
            "step 15 params [[0.3        0.47456633 0.24178126 0.5       ]\n",
            " [0.46130996 0.5        0.24178126 0.44627643]] loss 1.2554115443443568 predictions [tensor(0.72097459, requires_grad=True), tensor(0.71123375, requires_grad=True), tensor(0.72097459, requires_grad=True), tensor(0.71123375, requires_grad=True)]\n",
            "Iter:    16 | Cost: 1.2764524 | Accuracy: 1.0000000 \n",
            "step 16 [[0.3        0.47918617 0.24609544 0.5       ]\n",
            " [0.4660355  0.5        0.24609544 0.45078526]] 0.34075413855408837\n",
            "step 16 params [[0.3        0.47918617 0.24609544 0.5       ]\n",
            " [0.4660355  0.5        0.24609544 0.45078526]] loss 0.34075413855408837 predictions [tensor(0.71837032, requires_grad=True), tensor(0.70824655, requires_grad=True), tensor(0.71837032, requires_grad=True), tensor(0.70824655, requires_grad=True)]\n",
            "Iter:    17 | Cost: 1.2318462 | Accuracy: 1.0000000 \n",
            "step 17 [[0.3        0.48232581 0.24976692 0.5       ]\n",
            " [0.46960674 0.5        0.24976692 0.45454355]] 0.33077007528609403\n",
            "step 17 params [[0.3        0.48232581 0.24976692 0.5       ]\n",
            " [0.46960674 0.5        0.24976692 0.45454355]] loss 0.33077007528609403 predictions [tensor(0.71642761, requires_grad=True), tensor(0.70589328, requires_grad=True), tensor(0.71642761, requires_grad=True), tensor(0.70589328, requires_grad=True)]\n",
            "Iter:    18 | Cost: 0.3482912 | Accuracy: 1.0000000 \n",
            "step 18 [[0.3        0.48466331 0.25231841 0.5       ]\n",
            " [0.47217173 0.5        0.25231841 0.45718222]] 0.3482912099484531\n",
            "step 18 params [[0.3        0.48466331 0.25231841 0.5       ]\n",
            " [0.47217173 0.5        0.25231841 0.45718222]] loss 0.3482912099484531 predictions [tensor(0.71502744, requires_grad=True), tensor(0.70421979, requires_grad=True), tensor(0.71502744, requires_grad=True), tensor(0.70421979, requires_grad=True)]\n",
            "Iter:    19 | Cost: 1.2181386 | Accuracy: 1.0000000 \n",
            "step 19 [[0.3        0.48878859 0.25524109 0.5       ]\n",
            " [0.47602279 0.5        0.25524109 0.46038732]] 1.2553623747056557\n",
            "step 19 params [[0.3        0.48878859 0.25524109 0.5       ]\n",
            " [0.47602279 0.5        0.25524109 0.46038732]] loss 1.2553623747056557 predictions [tensor(0.71291128, requires_grad=True), tensor(0.7019342, requires_grad=True), tensor(0.71291128, requires_grad=True), tensor(0.7019342, requires_grad=True)]\n",
            "Iter:    20 | Cost: 0.3539156 | Accuracy: 1.0000000 \n",
            "step 20 [[0.3        0.49425271 0.25848731 0.5       ]\n",
            " [0.48092455 0.5        0.25848731 0.46409078]] 1.2479639773503384\n",
            "step 20 params [[0.3        0.49425271 0.25848731 0.5       ]\n",
            " [0.48092455 0.5        0.25848731 0.46409078]] loss 1.2479639773503384 predictions [tensor(0.71023168, requires_grad=True), tensor(0.69915303, requires_grad=True), tensor(0.71023168, requires_grad=True), tensor(0.69915303, requires_grad=True)]\n",
            "Iter:    21 | Cost: 0.3421640 | Accuracy: 1.0000000 \n",
            "step 21 [[0.3        0.50075631 0.26200916 0.5       ]\n",
            " [0.48669397 0.5        0.26200916 0.46822978]] 1.238673577682533\n",
            "step 21 params [[0.3        0.50075631 0.26200916 0.5       ]\n",
            " [0.48669397 0.5        0.26200916 0.46822978]] loss 1.238673577682533 predictions [tensor(0.70709798, requires_grad=True), tensor(0.69596569, requires_grad=True), tensor(0.70709798, requires_grad=True), tensor(0.69596569, requires_grad=True)]\n",
            "Iter:    22 | Cost: 1.1906147 | Accuracy: 1.0000000 \n",
            "step 22 [[0.3        0.50583354 0.26498852 0.5       ]\n",
            " [0.49129245 0.5        0.26498852 0.47166976]] 0.34658603561176576\n",
            "step 22 params [[0.3        0.50583354 0.26498852 0.5       ]\n",
            " [0.49129245 0.5        0.26498852 0.47166976]] loss 0.34658603561176576 predictions [tensor(0.70460489, requires_grad=True), tensor(0.69338539, requires_grad=True), tensor(0.70460489, requires_grad=True), tensor(0.69338539, requires_grad=True)]\n",
            "Iter:    23 | Cost: 1.2194415 | Accuracy: 1.0000000 \n",
            "step 23 [[0.3        0.51195247 0.26823246 0.5       ]\n",
            " [0.49676733 0.5        0.26823246 0.47555275]] 1.2194414587570166\n",
            "step 23 params [[0.3        0.51195247 0.26823246 0.5       ]\n",
            " [0.49676733 0.5        0.26823246 0.47555275]] loss 1.2194414587570166 predictions [tensor(0.70165545, requires_grad=True), tensor(0.69039909, requires_grad=True), tensor(0.70165545, requires_grad=True), tensor(0.69039909, requires_grad=True)]\n",
            "Iter:    24 | Cost: 0.3704855 | Accuracy: 1.0000000 \n",
            "step 24 [[0.3        0.51671982 0.27097117 0.5       ]\n",
            " [0.5011094  0.5        0.27097117 0.47876268]] 0.3543128066756202\n",
            "step 24 params [[0.3        0.51671982 0.27097117 0.5       ]\n",
            " [0.5011094  0.5        0.27097117 0.47876268]] loss 0.3543128066756202 predictions [tensor(0.69931926, requires_grad=True), tensor(0.68799264, requires_grad=True), tensor(0.69931926, requires_grad=True), tensor(0.68799264, requires_grad=True)]\n",
            "Iter:    25 | Cost: 1.1647285 | Accuracy: 1.0000000 \n",
            "step 25 [[0.3        0.52067617 0.2726457  0.5       ]\n",
            " [0.50445887 0.5        0.2726457  0.48088081]] 0.3739771345722296\n",
            "step 25 params [[0.3        0.52067617 0.2726457  0.5       ]\n",
            " [0.50445887 0.5        0.2726457  0.48088081]] loss 0.3739771345722296 predictions [tensor(0.69750579, requires_grad=True), tensor(0.68624667, requires_grad=True), tensor(0.69750579, requires_grad=True), tensor(0.68624667, requires_grad=True)]\n",
            "Iter:    26 | Cost: 1.1591482 | Accuracy: 1.0000000 \n",
            "step 26 [[0.3        0.52347119 0.27396331 0.5       ]\n",
            " [0.5068596  0.5        0.27396331 0.48248326]] 0.36024446400762833\n",
            "step 26 params [[0.3        0.52347119 0.27396331 0.5       ]\n",
            " [0.5068596  0.5        0.27396331 0.48248326]] loss 0.36024446400762833 predictions [tensor(0.69620342, requires_grad=True), tensor(0.68496638, requires_grad=True), tensor(0.69620342, requires_grad=True), tensor(0.68496638, requires_grad=True)]\n",
            "Iter:    27 | Cost: 1.1913969 | Accuracy: 1.0000000 \n",
            "step 27 [[0.3        0.52562456 0.27434618 0.5       ]\n",
            " [0.50843715 0.5        0.27434618 0.48313645]] 0.3783855228356731\n",
            "step 27 params [[0.3        0.52562456 0.27434618 0.5       ]\n",
            " [0.50843715 0.5        0.27434618 0.48313645]] loss 0.3783855228356731 predictions [tensor(0.69532991, requires_grad=True), tensor(0.68424361, requires_grad=True), tensor(0.69532991, requires_grad=True), tensor(0.68424361, requires_grad=True)]\n",
            "Iter:    28 | Cost: 0.3633689 | Accuracy: 1.0000000 \n",
            "step 28 [[0.3        0.5292143  0.27516355 0.5       ]\n",
            " [0.51125889 0.5        0.27516355 0.48447456]] 1.1885257654452102\n",
            "step 28 params [[0.3        0.5292143  0.27516355 0.5       ]\n",
            " [0.51125889 0.5        0.27516355 0.48447456]] loss 1.1885257654452102 predictions [tensor(0.6938041, requires_grad=True), tensor(0.68292591, requires_grad=True), tensor(0.6938041, requires_grad=True), tensor(0.68292591, requires_grad=True)]\n",
            "Iter:    29 | Cost: 0.3813689 | Accuracy: 1.0000000 \n",
            "step 29 [[0.3        0.53399443 0.27636525 0.5       ]\n",
            " [0.51514687 0.5        0.27636525 0.48642577]] 1.1835301718230606\n",
            "step 29 params [[0.3        0.53399443 0.27636525 0.5       ]\n",
            " [0.51514687 0.5        0.27636525 0.48642577]] loss 1.1835301718230606 predictions [tensor(0.69172394, requires_grad=True), tensor(0.68109684, requires_grad=True), tensor(0.69172394, requires_grad=True), tensor(0.68109684, requires_grad=True)]\n",
            "Iter:    30 | Cost: 0.3840508 | Accuracy: 1.0000000 \n",
            "step 30 [[0.3        0.53797964 0.27663326 0.5       ]\n",
            " [0.51809425 0.5        0.27663326 0.48738153]] 0.3840507764610341\n",
            "step 30 params [[0.3        0.53797964 0.27663326 0.5       ]\n",
            " [0.51809425 0.5        0.27663326 0.48738153]] loss 0.3840507764610341 predictions [tensor(0.69012904, requires_grad=True), tensor(0.67987035, requires_grad=True), tensor(0.69012904, requires_grad=True), tensor(0.67987035, requires_grad=True)]\n",
            "Iter:    31 | Cost: 1.1390292 | Accuracy: 1.0000000 \n",
            "step 31 [[0.3        0.54307782 0.27730219 0.5       ]\n",
            " [0.52207755 0.5        0.27730219 0.4889696 ]] 1.1715993158221336\n",
            "step 31 params [[0.3        0.54307782 0.27730219 0.5       ]\n",
            " [0.52207755 0.5        0.27730219 0.4889696 ]] loss 1.1715993158221336 predictions [tensor(0.68799736, requires_grad=True), tensor(0.67813989, requires_grad=True), tensor(0.68799736, requires_grad=True), tensor(0.67813989, requires_grad=True)]\n",
            "Iter:    32 | Cost: 0.3884017 | Accuracy: 1.0000000 \n",
            "step 32 [[0.3        0.54911269 0.2783181  0.5       ]\n",
            " [0.52695525 0.5        0.2783181  0.49112062]] 1.1647436224569332\n",
            "step 32 params [[0.3        0.54911269 0.2783181  0.5       ]\n",
            " [0.52695525 0.5        0.2783181  0.49112062]] loss 1.1647436224569332 predictions [tensor(0.68540407, requires_grad=True), tensor(0.67597481, requires_grad=True), tensor(0.68540407, requires_grad=True), tensor(0.67597481, requires_grad=True)]\n",
            "Iter:    33 | Cost: 0.3777467 | Accuracy: 1.0000000 \n",
            "step 33 [[0.3        0.55385023 0.27906886 0.5       ]\n",
            " [0.53075705 0.5        0.27906886 0.49275754]] 0.3777467361893918\n",
            "step 33 params [[0.3        0.55385023 0.27906886 0.5       ]\n",
            " [0.53075705 0.5        0.27906886 0.49275754]] loss 0.3777467361893918 predictions [tensor(0.68337515, requires_grad=True), tensor(0.67429823, requires_grad=True), tensor(0.68337515, requires_grad=True), tensor(0.67429823, requires_grad=True)]\n",
            "Iter:    34 | Cost: 1.1500377 | Accuracy: 1.0000000 \n",
            "step 34 [[0.3        0.55780613 0.2789202  0.5       ]\n",
            " [0.53363139 0.5        0.2789202  0.49340213]] 0.39408279336162305\n",
            "step 34 params [[0.3        0.55780613 0.2789202  0.5       ]\n",
            " [0.53363139 0.5        0.2789202  0.49340213]] loss 0.39408279336162305 predictions [tensor(0.68181928, requires_grad=True), tensor(0.67320844, requires_grad=True), tensor(0.68181928, requires_grad=True), tensor(0.67320844, requires_grad=True)]\n",
            "Iter:    35 | Cost: 0.3829906 | Accuracy: 1.0000000 \n",
            "step 35 [[0.3        0.56213446 0.28043089 0.5       ]\n",
            " [0.53737991 0.5        0.28043089 0.49562889]] 1.1184327427594594\n",
            "step 35 params [[0.3        0.56213446 0.28043089 0.5       ]\n",
            " [0.53737991 0.5        0.28043089 0.49562889]] loss 1.1184327427594594 predictions [tensor(0.67982172, requires_grad=True), tensor(0.67136476, requires_grad=True), tensor(0.67982172, requires_grad=True), tensor(0.67136476, requires_grad=True)]\n",
            "Iter:    36 | Cost: 1.1128068 | Accuracy: 1.0000000 \n",
            "step 36 [[0.3        0.56679896 0.28333286 0.5       ]\n",
            " [0.54189561 0.5        0.28333286 0.49918636]] 1.1128068213288826\n",
            "step 36 params [[0.3        0.56679896 0.28333286 0.5       ]\n",
            " [0.54189561 0.5        0.28333286 0.49918636]] loss 1.1128068213288826 predictions [tensor(0.67744992, requires_grad=True), tensor(0.66888588, requires_grad=True), tensor(0.67744992, requires_grad=True), tensor(0.66888588, requires_grad=True)]\n",
            "Iter:    37 | Cost: 0.4021418 | Accuracy: 1.0000000 \n",
            "step 37 [[0.3        0.57245245 0.2862657  0.5       ]\n",
            " [0.54721871 0.5        0.2862657  0.50303701]] 1.131496858134743\n",
            "step 37 params [[0.3        0.57245245 0.2862657  0.5       ]\n",
            " [0.54721871 0.5        0.2862657  0.50303701]] loss 1.131496858134743 predictions [tensor(0.67466499, requires_grad=True), tensor(0.66609232, requires_grad=True), tensor(0.67466499, requires_grad=True), tensor(0.66609232, requires_grad=True)]\n",
            "Iter:    38 | Cost: 1.1228998 | Accuracy: 1.0000000 \n",
            "step 38 [[0.3        0.5782886  0.2903607  0.5       ]\n",
            " [0.55310782 0.5        0.2903607  0.50797343]] 1.096890724409461\n",
            "step 38 params [[0.3        0.5782886  0.2903607  0.5       ]\n",
            " [0.55310782 0.5        0.2903607  0.50797343]] loss 1.096890724409461 predictions [tensor(0.67162462, requires_grad=True), tensor(0.66281145, requires_grad=True), tensor(0.67162462, requires_grad=True), tensor(0.66281145, requires_grad=True)]\n",
            "Iter:    39 | Cost: 1.1135979 | Accuracy: 1.0000000 \n",
            "step 39 [[0.3        0.58428335 0.29543374 0.5       ]\n",
            " [0.55948902 0.5        0.29543374 0.51382628]] 1.0871130128011355\n",
            "step 39 params [[0.3        0.58428335 0.29543374 0.5       ]\n",
            " [0.55948902 0.5        0.29543374 0.51382628]] loss 1.0871130128011355 predictions [tensor(0.66838027, requires_grad=True), tensor(0.65912724, requires_grad=True), tensor(0.66838027, requires_grad=True), tensor(0.65912724, requires_grad=True)]\n",
            "Iter:    40 | Cost: 1.0762460 | Accuracy: 1.0000000 \n",
            "step 40 [[0.3        0.59107491 0.30024699 0.5       ]\n",
            " [0.56642751 0.5        0.30024699 0.51969115]] 1.1037663627102001\n",
            "step 40 params [[0.3        0.59107491 0.30024699 0.5       ]\n",
            " [0.56642751 0.5        0.30024699 0.51969115]] loss 1.1037663627102001 predictions [tensor(0.66486595, requires_grad=True), tensor(0.65531004, requires_grad=True), tensor(0.66486595, requires_grad=True), tensor(0.65531004, requires_grad=True)]\n",
            "Iter:    41 | Cost: 0.4081698 | Accuracy: 1.0000000 \n",
            "step 41 [[0.3        0.59690369 0.30385925 0.5       ]\n",
            " [0.57216378 0.5        0.30385925 0.52421884]] 0.42264680987362946\n",
            "step 41 params [[0.3        0.59690369 0.30385925 0.5       ]\n",
            " [0.57216378 0.5        0.30385925 0.52421884]] loss 0.42264680987362946 predictions [tensor(0.6619587, requires_grad=True), tensor(0.65226232, requires_grad=True), tensor(0.6619587, requires_grad=True), tensor(0.65226232, requires_grad=True)]\n",
            "Iter:    42 | Cost: 1.0845872 | Accuracy: 1.0000000 \n",
            "step 42 [[0.3        0.60140934 0.30709086 0.5       ]\n",
            " [0.57673006 0.5        0.30709086 0.52807867]] 0.4125521059591548\n",
            "step 42 params [[0.3        0.60140934 0.30709086 0.5       ]\n",
            " [0.57673006 0.5        0.30709086 0.52807867]] loss 0.4125521059591548 predictions [tensor(0.65966804, requires_grad=True), tensor(0.6497678, requires_grad=True), tensor(0.65966804, requires_grad=True), tensor(0.6497678, requires_grad=True)]\n",
            "Iter:    43 | Cost: 1.0778338 | Accuracy: 1.0000000 \n",
            "step 43 [[0.3        0.60615579 0.31132108 0.5       ]\n",
            " [0.58188391 0.5        0.31132108 0.53293307]] 1.0491589147929414\n",
            "step 43 params [[0.3        0.60615579 0.31132108 0.5       ]\n",
            " [0.58188391 0.5        0.31132108 0.53293307]] loss 1.0491589147929414 predictions [tensor(0.65714163, requires_grad=True), tensor(0.64683342, requires_grad=True), tensor(0.65714163, requires_grad=True), tensor(0.64683342, requires_grad=True)]\n",
            "Iter:    44 | Cost: 1.0408154 | Accuracy: 1.0000000 \n",
            "step 44 [[0.3        0.61181931 0.31524661 0.5       ]\n",
            " [0.58770036 0.5        0.31524661 0.53783176]] 1.070437831402362\n",
            "step 44 params [[0.3        0.61181931 0.31524661 0.5       ]\n",
            " [0.58770036 0.5        0.31524661 0.53783176]] loss 1.070437831402362 predictions [tensor(0.65428615, requires_grad=True), tensor(0.64373222, requires_grad=True), tensor(0.65428615, requires_grad=True), tensor(0.64373222, requires_grad=True)]\n",
            "Iter:    45 | Cost: 0.4404725 | Accuracy: 1.0000000 \n",
            "step 45 [[0.3        0.61758793 0.32004736 0.5       ]\n",
            " [0.59394776 0.5        0.32004736 0.54357374]] 1.0320726259813653\n",
            "step 45 params [[0.3        0.61758793 0.32004736 0.5       ]\n",
            " [0.59394776 0.5        0.32004736 0.54357374]] loss 1.0320726259813653 predictions [tensor(0.65128793, requires_grad=True), tensor(0.64029482, requires_grad=True), tensor(0.65128793, requires_grad=True), tensor(0.64029482, requires_grad=True)]\n",
            "Iter:    46 | Cost: 1.0224705 | Accuracy: 1.0000000 \n",
            "step 46 [[0.3        0.62248528 0.32367562 0.5       ]\n",
            " [0.59904936 0.5        0.32367562 0.54799176]] 0.4458265596953968\n",
            "step 46 params [[0.3        0.62248528 0.32367562 0.5       ]\n",
            " [0.59904936 0.5        0.32367562 0.54799176]] loss 0.4458265596953968 predictions [tensor(0.64883668, requires_grad=True), tensor(0.63757811, requires_grad=True), tensor(0.64883668, requires_grad=True), tensor(0.63757811, requires_grad=True)]\n",
            "Iter:    47 | Cost: 1.0149463 | Accuracy: 1.0000000 \n",
            "step 47 [[0.3        0.62612427 0.32699659 0.5       ]\n",
            " [0.60302808 0.5        0.32699659 0.55177853]] 0.43257425018163564\n",
            "step 47 params [[0.3        0.62612427 0.32699659 0.5       ]\n",
            " [0.60302808 0.5        0.32699659 0.55177853]] loss 0.43257425018163564 predictions [tensor(0.64696332, requires_grad=True), tensor(0.63536731, requires_grad=True), tensor(0.64696332, requires_grad=True), tensor(0.63536731, requires_grad=True)]\n",
            "Iter:    48 | Cost: 0.4354657 | Accuracy: 1.0000000 \n",
            "step 48 [[0.3        0.63003892 0.33119814 0.5       ]\n",
            " [0.60760415 0.5        0.33119814 0.55649664]] 1.0088647595209117\n",
            "step 48 params [[0.3        0.63003892 0.33119814 0.5       ]\n",
            " [0.60760415 0.5        0.33119814 0.55649664]] loss 1.0088647595209117 predictions [tensor(0.64487228, requires_grad=True), tensor(0.6327555, requires_grad=True), tensor(0.64487228, requires_grad=True), tensor(0.6327555, requires_grad=True)]\n",
            "Iter:    49 | Cost: 0.4576712 | Accuracy: 1.0000000 \n",
            "step 49 [[0.3        0.63277786 0.33506824 0.5       ]\n",
            " [0.61110132 0.5        0.33506824 0.56056576]] 0.4387030002756657\n",
            "step 49 params [[0.3        0.63277786 0.33506824 0.5       ]\n",
            " [0.61110132 0.5        0.33506824 0.56056576]] loss 0.4387030002756657 predictions [tensor(0.64332902, requires_grad=True), tensor(0.63063377, requires_grad=True), tensor(0.64332902, requires_grad=True), tensor(0.63063377, requires_grad=True)]\n",
            "Iter:    50 | Cost: 1.0309416 | Accuracy: 1.0000000 \n",
            "step 50 [[0.3        0.63491609 0.3378615  0.5       ]\n",
            " [0.61369496 0.5        0.3378615  0.56346005]] 0.4610299735772336\n",
            "step 50 params [[0.3        0.63491609 0.3378615  0.5       ]\n",
            " [0.61369496 0.5        0.3378615  0.56346005]] loss 0.4610299735772336 predictions [tensor(0.64217766, requires_grad=True), tensor(0.62909077, requires_grad=True), tensor(0.64217766, requires_grad=True), tensor(0.62909077, requires_grad=True)]\n",
            "Iter:    51 | Cost: 0.4634797 | Accuracy: 1.0000000 \n",
            "step 51 [[0.3        0.63824296 0.34028926 0.5       ]\n",
            " [0.61718502 0.5        0.34028926 0.56648981]] 1.0277186851400932\n",
            "step 51 params [[0.3        0.63824296 0.34028926 0.5       ]\n",
            " [0.61718502 0.5        0.34028926 0.56648981]] loss 1.0277186851400932 predictions [tensor(0.64056925, requires_grad=True), tensor(0.62729824, requires_grad=True), tensor(0.64056925, requires_grad=True), tensor(0.62729824, requires_grad=True)]\n",
            "Iter:    52 | Cost: 0.4663332 | Accuracy: 1.0000000 \n",
            "step 52 [[0.3        0.64260318 0.34236176 0.5       ]\n",
            " [0.62146699 0.5        0.34236176 0.5696361 ]] 1.0232337590393403\n",
            "step 52 params [[0.3        0.64260318 0.34236176 0.5       ]\n",
            " [0.62146699 0.5        0.34236176 0.5696361 ]] loss 1.0232337590393403 predictions [tensor(0.63856189, requires_grad=True), tensor(0.62529507, requires_grad=True), tensor(0.63856189, requires_grad=True), tensor(0.62529507, requires_grad=True)]\n",
            "Iter:    53 | Cost: 1.0176644 | Accuracy: 1.0000000 \n",
            "step 53 [[0.3        0.64712941 0.34539186 0.5       ]\n",
            " [0.62627949 0.5        0.34539186 0.57376023]] 0.9816164200791068\n",
            "step 53 params [[0.3        0.64712941 0.34539186 0.5       ]\n",
            " [0.62627949 0.5        0.34539186 0.57376023]] loss 0.9816164200791068 predictions [tensor(0.63638606, requires_grad=True), tensor(0.62290762, requires_grad=True), tensor(0.63638606, requires_grad=True), tensor(0.62290762, requires_grad=True)]\n",
            "Iter:    54 | Cost: 0.9752651 | Accuracy: 1.0000000 \n",
            "step 54 [[0.3        0.6518014  0.34924886 0.5       ]\n",
            " [0.6315613  0.5        0.34924886 0.57873391]] 0.975265071677357\n",
            "step 54 params [[0.3        0.6518014  0.34924886 0.5       ]\n",
            " [0.6315613  0.5        0.34924886 0.57873391]] loss 0.975265071677357 predictions [tensor(0.63407602, requires_grad=True), tensor(0.62019737, requires_grad=True), tensor(0.63407602, requires_grad=True), tensor(0.62019737, requires_grad=True)]\n",
            "Iter:    55 | Cost: 1.0053297 | Accuracy: 1.0000000 \n",
            "step 55 [[0.3        0.65521485 0.35288768 0.5       ]\n",
            " [0.63568992 0.5        0.35288768 0.58305868]] 0.4555864220313945\n",
            "step 55 params [[0.3        0.65521485 0.35288768 0.5       ]\n",
            " [0.63568992 0.5        0.35288768 0.58305868]] loss 0.4555864220313945 predictions [tensor(0.63233791, requires_grad=True), tensor(0.6179729, requires_grad=True), tensor(0.63233791, requires_grad=True), tensor(0.6179729, requires_grad=True)]\n",
            "Iter:    56 | Cost: 0.9622637 | Accuracy: 1.0000000 \n",
            "step 56 [[0.3        0.65886329 0.35724794 0.5       ]\n",
            " [0.64034125 0.5        0.35724794 0.5881886 ]] 0.9622637280496275\n",
            "step 56 params [[0.3        0.65886329 0.35724794 0.5       ]\n",
            " [0.64034125 0.5        0.35724794 0.5881886 ]] loss 0.9622637280496275 predictions [tensor(0.63044471, requires_grad=True), tensor(0.61543419, requires_grad=True), tensor(0.63044471, requires_grad=True), tensor(0.61543419, requires_grad=True)]\n",
            "Iter:    57 | Cost: 0.9954549 | Accuracy: 1.0000000 \n",
            "step 57 [[0.3        0.66271781 0.36222876 0.5       ]\n",
            " [0.64545364 0.5        0.36222876 0.5940169 ]] 0.955640357200405\n",
            "step 57 params [[0.3        0.66271781 0.36222876 0.5       ]\n",
            " [0.64545364 0.5        0.36222876 0.5940169 ]] loss 0.955640357200405 predictions [tensor(0.62842999, requires_grad=True), tensor(0.61263496, requires_grad=True), tensor(0.62842999, requires_grad=True), tensor(0.61263496, requires_grad=True)]\n",
            "Iter:    58 | Cost: 0.9483878 | Accuracy: 1.0000000 \n",
            "step 58 [[0.3        0.6667507  0.36773832 0.5       ]\n",
            " [0.65097052 0.5        0.36773832 0.60044859]] 0.9483877737847256\n",
            "step 58 params [[0.3        0.6667507  0.36773832 0.5       ]\n",
            " [0.65097052 0.5        0.36773832 0.60044859]] loss 0.9483877737847256 predictions [tensor(0.62632511, requires_grad=True), tensor(0.6096246, requires_grad=True), tensor(0.62632511, requires_grad=True), tensor(0.6096246, requires_grad=True)]\n",
            "Iter:    59 | Cost: 0.9406464 | Accuracy: 1.0000000 \n",
            "step 59 [[0.3        0.67007793 0.3720867  0.5       ]\n",
            " [0.6553967  0.5        0.3720867  0.60549359]] 0.494911919483788\n",
            "step 59 params [[0.3        0.67007793 0.3720867  0.5       ]\n",
            " [0.6553967  0.5        0.3720867  0.60549359]] loss 0.494911919483788 predictions [tensor(0.62465155, requires_grad=True), tensor(0.6072581, requires_grad=True), tensor(0.62465155, requires_grad=True), tensor(0.6072581, requires_grad=True)]\n",
            "Iter:    60 | Cost: 0.9799005 | Accuracy: 1.0000000 \n",
            "step 60 [[0.3        0.6727641  0.37539103 0.5       ]\n",
            " [0.65883165 0.5        0.37539103 0.60928412]] 0.498801372795859\n",
            "step 60 params [[0.3        0.6727641  0.37539103 0.5       ]\n",
            " [0.65883165 0.5        0.37539103 0.60928412]] loss 0.498801372795859 predictions [tensor(0.62335238, requires_grad=True), tensor(0.60545922, requires_grad=True), tensor(0.62335238, requires_grad=True), tensor(0.60545922, requires_grad=True)]\n",
            "Iter:    61 | Cost: 0.4726433 | Accuracy: 1.0000000 \n",
            "step 61 [[0.3        0.67435045 0.3786396  0.5       ]\n",
            " [0.66127877 0.5        0.3786396  0.6125692 ]] 0.4726432969719202\n",
            "step 61 params [[0.3        0.67435045 0.3786396  0.5       ]\n",
            " [0.66127877 0.5        0.3786396  0.6125692 ]] loss 0.4726432969719202 predictions [tensor(0.62252456, requires_grad=True), tensor(0.60402857, requires_grad=True), tensor(0.62252456, requires_grad=True), tensor(0.60402857, requires_grad=True)]\n",
            "Iter:    62 | Cost: 0.9264132 | Accuracy: 1.0000000 \n",
            "step 62 [[0.3        0.67494325 0.3818512  0.5       ]\n",
            " [0.66282954 0.5        0.3818512  0.61539682]] 0.4739722002685836\n",
            "step 62 params [[0.3        0.67494325 0.3818512  0.5       ]\n",
            " [0.66282954 0.5        0.3818512  0.61539682]] loss 0.4739722002685836 predictions [tensor(0.62211879, requires_grad=True), tensor(0.6029246, requires_grad=True), tensor(0.62211879, requires_grad=True), tensor(0.6029246, requires_grad=True)]\n",
            "Iter:    63 | Cost: 0.9236291 | Accuracy: 1.0000000 \n",
            "step 63 [[0.3        0.67463938 0.38504011 0.5       ]\n",
            " [0.66356765 0.5        0.38504011 0.61780976]] 0.47462423101503465\n",
            "step 63 params [[0.3        0.67463938 0.38504011 0.5       ]\n",
            " [0.66356765 0.5        0.38504011 0.61780976]] loss 0.47462423101503465 predictions [tensor(0.62209028, requires_grad=True), tensor(0.6021106, requires_grad=True), tensor(0.62209028, requires_grad=True), tensor(0.6021106, requires_grad=True)]\n",
            "Iter:    64 | Cost: 0.5073141 | Accuracy: 1.0000000 \n",
            "step 64 [[0.3        0.67573087 0.38747551 0.5       ]\n",
            " [0.66531866 0.5        0.38747551 0.62026163]] 0.9730999475576824\n",
            "step 64 params [[0.3        0.67573087 0.38747551 0.5       ]\n",
            " [0.66531866 0.5        0.38747551 0.62026163]] loss 0.9730999475576824 predictions [tensor(0.62153077, requires_grad=True), tensor(0.60108124, requires_grad=True), tensor(0.62153077, requires_grad=True), tensor(0.60108124, requires_grad=True)]\n",
            "Iter:    65 | Cost: 0.5090252 | Accuracy: 1.0000000 \n",
            "step 65 [[0.3        0.67639443 0.38904525 0.5       ]\n",
            " [0.66632478 0.5        0.38904525 0.62168359]] 0.5090251822792382\n",
            "step 65 params [[0.3        0.67639443 0.38904525 0.5       ]\n",
            " [0.66632478 0.5        0.38904525 0.62168359]] loss 0.5090251822792382 predictions [tensor(0.62121216, requires_grad=True), tensor(0.60047115, requires_grad=True), tensor(0.62121216, requires_grad=True), tensor(0.60047115, requires_grad=True)]\n",
            "Iter:    66 | Cost: 0.9707790 | Accuracy: 1.0000000 \n",
            "step 66 [[0.3        0.67833984 0.38998217 0.5       ]\n",
            " [0.66831306 0.5        0.38998217 0.62322849]] 0.970779029686789\n",
            "step 66 params [[0.3        0.67833984 0.38998217 0.5       ]\n",
            " [0.66831306 0.5        0.38998217 0.62322849]] loss 0.970779029686789 predictions [tensor(0.62039345, requires_grad=True), tensor(0.59963421, requires_grad=True), tensor(0.62039345, requires_grad=True), tensor(0.59963421, requires_grad=True)]\n",
            "Iter:    67 | Cost: 0.4774014 | Accuracy: 1.0000000 \n",
            "step 67 [[0.3        0.67978086 0.39019573 0.5       ]\n",
            " [0.66953281 0.5        0.39019573 0.62382264]] 0.5114354653804272\n",
            "step 67 params [[0.3        0.67978086 0.39019573 0.5       ]\n",
            " [0.66953281 0.5        0.39019573 0.62382264]] loss 0.5114354653804272 predictions [tensor(0.61983382, requires_grad=True), tensor(0.59919452, requires_grad=True), tensor(0.61983382, requires_grad=True), tensor(0.59919452, requires_grad=True)]\n",
            "Iter:    68 | Cost: 0.4783039 | Accuracy: 1.0000000 \n",
            "step 68 [[0.3        0.68157806 0.39133209 0.5       ]\n",
            " [0.67150479 0.5        0.39133209 0.62554707]] 0.9142790453001239\n",
            "step 68 params [[0.3        0.68157806 0.39133209 0.5       ]\n",
            " [0.67150479 0.5        0.39133209 0.62554707]] loss 0.9142790453001239 predictions [tensor(0.61905792, requires_grad=True), tensor(0.59832885, requires_grad=True), tensor(0.61905792, requires_grad=True), tensor(0.59832885, requires_grad=True)]\n",
            "Iter:    69 | Cost: 0.9651079 | Accuracy: 1.0000000 \n",
            "step 69 [[0.3        0.68288019 0.39173257 0.5       ]\n",
            " [0.67270502 0.5        0.39173257 0.62630546]] 0.5136147553434671\n",
            "step 69 params [[0.3        0.68288019 0.39173257 0.5       ]\n",
            " [0.67270502 0.5        0.39173257 0.62630546]] loss 0.5136147553434671 predictions [tensor(0.61853752, requires_grad=True), tensor(0.59786166, requires_grad=True), tensor(0.61853752, requires_grad=True), tensor(0.59786166, requires_grad=True)]\n",
            "Iter:    70 | Cost: 0.5143959 | Accuracy: 1.0000000 \n",
            "step 70 [[0.3        0.68455409 0.39302292 0.5       ]\n",
            " [0.67466088 0.5        0.39302292 0.62816778]] 0.9109591246302184\n",
            "step 70 params [[0.3        0.68455409 0.39302292 0.5       ]\n",
            " [0.67466088 0.5        0.39302292 0.62816778]] loss 0.9109591246302184 predictions [tensor(0.61779986, requires_grad=True), tensor(0.59697751, requires_grad=True), tensor(0.61779986, requires_grad=True), tensor(0.59697751, requires_grad=True)]\n",
            "Iter:    71 | Cost: 0.5158758 | Accuracy: 1.0000000 \n",
            "step 71 [[0.3        0.68520662 0.39453445 0.5       ]\n",
            " [0.67575261 0.5        0.39453445 0.62971692]] 0.4815907323535994\n",
            "step 71 params [[0.3        0.68520662 0.39453445 0.5       ]\n",
            " [0.67575261 0.5        0.39453445 0.62971692]] loss 0.4815907323535994 predictions [tensor(0.61747572, requires_grad=True), tensor(0.59635353, requires_grad=True), tensor(0.61747572, requires_grad=True), tensor(0.59635353, requires_grad=True)]\n",
            "Iter:    72 | Cost: 0.4821155 | Accuracy: 1.0000000 \n",
            "step 72 [[0.3        0.68546625 0.39527941 0.5       ]\n",
            " [0.67614916 0.5        0.39527941 0.63031268]] 0.5169216207795698\n",
            "step 72 params [[0.3        0.68546625 0.39527941 0.5       ]\n",
            " [0.67614916 0.5        0.39527941 0.63031268]] loss 0.5169216207795698 predictions [tensor(0.61736322, requires_grad=True), tensor(0.59610268, requires_grad=True), tensor(0.61736322, requires_grad=True), tensor(0.59610268, requires_grad=True)]\n",
            "Iter:    73 | Cost: 0.9606691 | Accuracy: 1.0000000 \n",
            "step 73 [[0.3        0.68536692 0.39532792 0.5       ]\n",
            " [0.67591304 0.5        0.39532792 0.63004551]] 0.5173423369654132\n",
            "step 73 params [[0.3        0.68536692 0.39532792 0.5       ]\n",
            " [0.67591304 0.5        0.39532792 0.63004551]] loss 0.5173423369654132 predictions [tensor(0.61744166, requires_grad=True), tensor(0.59618898, requires_grad=True), tensor(0.61744166, requires_grad=True), tensor(0.59618898, requires_grad=True)]\n",
            "Iter:    74 | Cost: 0.9068083 | Accuracy: 1.0000000 \n",
            "step 74 [[0.3        0.68493875 0.39474114 0.5       ]\n",
            " [0.67510053 0.5        0.39474114 0.62899668]] 0.5171975765172598\n",
            "step 74 params [[0.3        0.68493875 0.39474114 0.5       ]\n",
            " [0.67510053 0.5        0.39474114 0.62899668]] loss 0.5171975765172598 predictions [tensor(0.61769454, requires_grad=True), tensor(0.59658218, requires_grad=True), tensor(0.61769454, requires_grad=True), tensor(0.59658218, requires_grad=True)]\n",
            "Iter:    75 | Cost: 0.9615354 | Accuracy: 1.0000000 \n",
            "step 75 [[0.3        0.68367212 0.3945614  0.5       ]\n",
            " [0.67367325 0.5        0.3945614  0.62790024]] 0.48176121421132456\n",
            "step 75 params [[0.3        0.68367212 0.3945614  0.5       ]\n",
            " [0.67367325 0.5        0.3945614  0.62790024]] loss 0.48176121421132456 predictions [tensor(0.61827076, requires_grad=True), tensor(0.59711589, requires_grad=True), tensor(0.61827076, requires_grad=True), tensor(0.59711589, requires_grad=True)]\n",
            "Iter:    76 | Cost: 0.9630437 | Accuracy: 1.0000000 \n",
            "step 76 [[0.3        0.68164826 0.39474796 0.5       ]\n",
            " [0.67168727 0.5        0.39474796 0.62675777]] 0.480828798945051\n",
            "step 76 params [[0.3        0.68164826 0.39474796 0.5       ]\n",
            " [0.67168727 0.5        0.39474796 0.62675777]] loss 0.480828798945051 predictions [tensor(0.61913898, requires_grad=True), tensor(0.59777748, requires_grad=True), tensor(0.61913898, requires_grad=True), tensor(0.59777748, requires_grad=True)]\n",
            "Iter:    77 | Cost: 0.9653208 | Accuracy: 1.0000000 \n",
            "step 77 [[0.3        0.67894156 0.39526194 0.5       ]\n",
            " [0.66919428 0.5        0.39526194 0.62557014]] 0.479425500182578\n",
            "step 77 params [[0.3        0.67894156 0.39526194 0.5       ]\n",
            " [0.66919428 0.5        0.39526194 0.62557014]] loss 0.479425500182578 predictions [tensor(0.6202696, requires_grad=True), tensor(0.5985551, requires_grad=True), tensor(0.6202696, requires_grad=True), tensor(0.5985551, requires_grad=True)]\n",
            "Iter:    78 | Cost: 0.9682937 | Accuracy: 1.0000000 \n",
            "step 78 [[0.3        0.67562007 0.39606629 0.5       ]\n",
            " [0.66624192 0.5        0.39606629 0.62433768]] 0.477601061943045\n",
            "step 78 params [[0.3        0.67562007 0.39606629 0.5       ]\n",
            " [0.66624192 0.5        0.39606629 0.62433768]] loss 0.477601061943045 predictions [tensor(0.62163473, requires_grad=True), tensor(0.59943766, requires_grad=True), tensor(0.62163473, requires_grad=True), tensor(0.59943766, requires_grad=True)]\n",
            "Iter:    79 | Cost: 0.5117633 | Accuracy: 1.0000000 \n",
            "step 79 [[0.3        0.67174603 0.39712572 0.5       ]\n",
            " [0.66287407 0.5        0.39712572 0.62306022]] 0.475402608051898\n",
            "step 79 params [[0.3        0.67174603 0.39712572 0.5       ]\n",
            " [0.66287407 0.5        0.39712572 0.62306022]] loss 0.475402608051898 predictions [tensor(0.62320831, requires_grad=True), tensor(0.60041489, requires_grad=True), tensor(0.62320831, requires_grad=True), tensor(0.60041489, requires_grad=True)]\n",
            "Iter:    80 | Cost: 0.5101344 | Accuracy: 1.0000000 \n",
            "step 80 [[0.3        0.66972448 0.39755761 0.5       ]\n",
            " [0.66099714 0.5        0.39755761 0.62217051]] 0.9760627976271151\n",
            "step 80 params [[0.3        0.66972448 0.39755761 0.5       ]\n",
            " [0.66099714 0.5        0.39755761 0.62217051]] loss 0.9760627976271151 predictions [tensor(0.62405302, requires_grad=True), tensor(0.60099233, requires_grad=True), tensor(0.62405302, requires_grad=True), tensor(0.60099233, requires_grad=True)]\n",
            "Iter:    81 | Cost: 0.9783072 | Accuracy: 1.0000000 \n",
            "step 81 [[0.3        0.66703578 0.39826388 0.5       ]\n",
            " [0.65860607 0.5        0.39826388 0.62119643]] 0.4715199466716703\n",
            "step 81 params [[0.3        0.66703578 0.39826388 0.5       ]\n",
            " [0.65860607 0.5        0.39826388 0.62119643]] loss 0.4715199466716703 predictions [tensor(0.62515283, requires_grad=True), tensor(0.60169478, requires_grad=True), tensor(0.62515283, requires_grad=True), tensor(0.60169478, requires_grad=True)]\n",
            "Iter:    82 | Cost: 0.5080050 | Accuracy: 1.0000000 \n",
            "step 82 [[0.3        0.66374647 0.39921243 0.5       ]\n",
            " [0.65574957 0.5        0.39921243 0.62014199]] 0.46975912581915624\n",
            "step 82 params [[0.3        0.66374647 0.39921243 0.5       ]\n",
            " [0.65574957 0.5        0.39921243 0.62014199]] loss 0.46975912581915624 predictions [tensor(0.62648047, requires_grad=True), tensor(0.60251019, requires_grad=True), tensor(0.62648047, requires_grad=True), tensor(0.60251019, requires_grad=True)]\n",
            "Iter:    83 | Cost: 0.4676377 | Accuracy: 1.0000000 \n",
            "step 83 [[0.3        0.66041751 0.39930944 0.5       ]\n",
            " [0.65255181 0.5        0.39930944 0.61832775]] 0.5066507012728911\n",
            "step 83 params [[0.3        0.66041751 0.39930944 0.5       ]\n",
            " [0.65255181 0.5        0.39930944 0.61832775]] loss 0.5066507012728911 predictions [tensor(0.62787151, requires_grad=True), tensor(0.6035969, requires_grad=True), tensor(0.62787151, requires_grad=True), tensor(0.6035969, requires_grad=True)]\n",
            "Iter:    84 | Cost: 0.5048487 | Accuracy: 1.0000000 \n",
            "step 84 [[0.3        0.6579328  0.40056981 0.5       ]\n",
            " [0.65060323 0.5        0.40056981 0.61801049]] 0.9253236511049406\n",
            "step 84 params [[0.3        0.6579328  0.40056981 0.5       ]\n",
            " [0.65060323 0.5        0.40056981 0.61801049]] loss 0.9253236511049406 predictions [tensor(0.62883328, requires_grad=True), tensor(0.60404046, requires_grad=True), tensor(0.62883328, requires_grad=True), tensor(0.60404046, requires_grad=True)]\n",
            "Iter:    85 | Cost: 0.9264432 | Accuracy: 1.0000000 \n",
            "step 85 [[0.3        0.65532901 0.4009263  0.5       ]\n",
            " [0.64822568 0.5        0.4009263  0.61686646]] 0.5041141026534404\n",
            "step 85 params [[0.3        0.65532901 0.4009263  0.5       ]\n",
            " [0.64822568 0.5        0.4009263  0.61686646]] loss 0.5041141026534404 predictions [tensor(0.62989503, requires_grad=True), tensor(0.60479448, requires_grad=True), tensor(0.62989503, requires_grad=True), tensor(0.60479448, requires_grad=True)]\n",
            "Iter:    86 | Cost: 0.4622021 | Accuracy: 1.0000000 \n",
            "step 86 [[0.3        0.65351102 0.40245254 0.5       ]\n",
            " [0.64702334 0.5        0.40245254 0.61714696]] 0.9283493424377195\n",
            "step 86 params [[0.3        0.65351102 0.40245254 0.5       ]\n",
            " [0.64702334 0.5        0.40245254 0.61714696]] loss 0.9283493424377195 predictions [tensor(0.63055496, requires_grad=True), tensor(0.60493022, requires_grad=True), tensor(0.63055496, requires_grad=True), tensor(0.60493022, requires_grad=True)]\n",
            "Iter:    87 | Cost: 0.9286929 | Accuracy: 1.0000000 \n",
            "step 87 [[0.3        0.65099854 0.40410306 0.5       ]\n",
            " [0.64524367 0.5        0.40410306 0.61722032]] 0.4611549647572211\n",
            "step 87 params [[0.3        0.65099854 0.40410306 0.5       ]\n",
            " [0.64524367 0.5        0.40410306 0.61722032]] loss 0.4611549647572211 predictions [tensor(0.63148008, requires_grad=True), tensor(0.60523541, requires_grad=True), tensor(0.63148008, requires_grad=True), tensor(0.60523541, requires_grad=True)]\n",
            "Iter:    88 | Cost: 0.9294657 | Accuracy: 1.0000000 \n",
            "step 88 [[0.3        0.64926587 0.4068157  0.5       ]\n",
            " [0.64458139 0.5        0.4068157  0.61859007]] 0.9294656557827844\n",
            "step 88 params [[0.3        0.64926587 0.4068157  0.5       ]\n",
            " [0.64458139 0.5        0.4068157  0.61859007]] loss 0.9294656557827844 predictions [tensor(0.63201589, requires_grad=True), tensor(0.60496335, requires_grad=True), tensor(0.63201589, requires_grad=True), tensor(0.60496335, requires_grad=True)]\n",
            "Iter:    89 | Cost: 0.5025874 | Accuracy: 1.0000000 \n",
            "step 89 [[0.3        0.6468324  0.40953749 0.5       ]\n",
            " [0.64329414 0.5        0.40953749 0.61965088]] 0.45884074601224045\n",
            "step 89 params [[0.3        0.6468324  0.40953749 0.5       ]\n",
            " [0.64329414 0.5        0.40953749 0.61965088]] loss 0.45884074601224045 predictions [tensor(0.63282456, requires_grad=True), tensor(0.60489639, requires_grad=True), tensor(0.63282456, requires_grad=True), tensor(0.60489639, requires_grad=True)]\n",
            "Iter:    90 | Cost: 1.0019155 | Accuracy: 1.0000000 \n",
            "step 90 [[0.3        0.64377054 0.41226684 0.5       ]\n",
            " [0.64144369 0.5        0.41226684 0.62042978]] 0.4575620546838315\n",
            "step 90 params [[0.3        0.64377054 0.41226684 0.5       ]\n",
            " [0.64144369 0.5        0.41226684 0.62042978]] loss 0.4575620546838315 predictions [tensor(0.63387425, requires_grad=True), tensor(0.60501163, requires_grad=True), tensor(0.63387425, requires_grad=True), tensor(0.60501163, requires_grad=True)]\n",
            "Iter:    91 | Cost: 0.5025076 | Accuracy: 1.0000000 \n",
            "step 91 [[0.3        0.64153655 0.41598495 0.5       ]\n",
            " [0.64071301 0.5        0.41598495 0.62243057]] 0.9288989510186488\n",
            "step 91 params [[0.3        0.64153655 0.41598495 0.5       ]\n",
            " [0.64071301 0.5        0.41598495 0.62243057]] loss 0.9288989510186488 predictions [tensor(0.63452732, requires_grad=True), tensor(0.60456714, requires_grad=True), tensor(0.63452732, requires_grad=True), tensor(0.60456714, requires_grad=True)]\n",
            "Iter:    92 | Cost: 0.9277743 | Accuracy: 1.0000000 \n",
            "step 92 [[0.3        0.64004992 0.4205862  0.5       ]\n",
            " [0.64098469 0.5        0.4205862  0.62550987]] 0.927774264528005\n",
            "step 92 params [[0.3        0.64004992 0.4205862  0.5       ]\n",
            " [0.64098469 0.5        0.4205862  0.62550987]] loss 0.927774264528005 predictions [tensor(0.63483244, requires_grad=True), tensor(0.60362981, requires_grad=True), tensor(0.63483244, requires_grad=True), tensor(0.60362981, requires_grad=True)]\n",
            "Iter:    93 | Cost: 0.9254067 | Accuracy: 1.0000000 \n",
            "step 93 [[0.3        0.63835286 0.42390314 0.5       ]\n",
            " [0.64062348 0.5        0.42390314 0.62744783]] 0.5047941694077852\n",
            "step 93 params [[0.3        0.63835286 0.42390314 0.5       ]\n",
            " [0.64062348 0.5        0.42390314 0.62744783]] loss 0.5047941694077852 predictions [tensor(0.63529341, requires_grad=True), tensor(0.60313753, requires_grad=True), tensor(0.63529341, requires_grad=True), tensor(0.60313753, requires_grad=True)]\n",
            "Iter:    94 | Cost: 0.9241655 | Accuracy: 1.0000000 \n",
            "step 94 [[0.3        0.63832089 0.42644888 0.5       ]\n",
            " [0.64146142 0.5        0.42644888 0.62951603]] 1.008662102596171\n",
            "step 94 params [[0.3        0.63832089 0.42644888 0.5       ]\n",
            " [0.64146142 0.5        0.42644888 0.62951603]] loss 1.008662102596171 predictions [tensor(0.63516685, requires_grad=True), tensor(0.60239391, requires_grad=True), tensor(0.63516685, requires_grad=True), tensor(0.60239391, requires_grad=True)]\n",
            "Iter:    95 | Cost: 0.4538676 | Accuracy: 1.0000000 \n",
            "step 95 [[0.3        0.63975267 0.42828181 0.5       ]\n",
            " [0.64336662 0.5        0.42828181 0.63170003]] 1.008315147857118\n",
            "step 95 params [[0.3        0.63975267 0.42828181 0.5       ]\n",
            " [0.64336662 0.5        0.42828181 0.63170003]] loss 1.008315147857118 predictions [tensor(0.63452505, requires_grad=True), tensor(0.60143567, requires_grad=True), tensor(0.63452505, requires_grad=True), tensor(0.60143567, requires_grad=True)]\n",
            "Iter:    96 | Cost: 0.9198864 | Accuracy: 1.0000000 \n",
            "step 96 [[0.3        0.64071169 0.42909671 0.5       ]\n",
            " [0.64449082 0.5        0.42909671 0.63282382]] 0.5084356970610406\n",
            "step 96 params [[0.3        0.64071169 0.42909671 0.5       ]\n",
            " [0.64449082 0.5        0.42909671 0.63282382]] loss 0.5084356970610406 predictions [tensor(0.63412124, requires_grad=True), tensor(0.60091946, requires_grad=True), tensor(0.63412124, requires_grad=True), tensor(0.60091946, requires_grad=True)]\n",
            "Iter:    97 | Cost: 0.4555151 | Accuracy: 1.0000000 \n",
            "step 97 [[0.3        0.6430165  0.42933104 0.5       ]\n",
            " [0.64664836 0.5        0.42933104 0.63414386]] 1.0054532498287407\n",
            "step 97 params [[0.3        0.6430165  0.42933104 0.5       ]\n",
            " [0.64664836 0.5        0.42933104 0.63414386]] loss 1.0054532498287407 predictions [tensor(0.63323064, requires_grad=True), tensor(0.60017337, requires_grad=True), tensor(0.63323064, requires_grad=True), tensor(0.60017337, requires_grad=True)]\n",
            "Iter:    98 | Cost: 0.5105367 | Accuracy: 1.0000000 \n",
            "step 98 [[0.3        0.64476859 0.42871126 0.5       ]\n",
            " [0.64799964 0.5        0.42871126 0.63448119]] 0.5105367155985059\n",
            "step 98 params [[0.3        0.64476859 0.42871126 0.5       ]\n",
            " [0.64799964 0.5        0.42871126 0.63448119]] loss 0.5105367155985059 predictions [tensor(0.63259543, requires_grad=True), tensor(0.59984281, requires_grad=True), tensor(0.63259543, requires_grad=True), tensor(0.59984281, requires_grad=True)]\n",
            "Iter:    99 | Cost: 1.0012917 | Accuracy: 1.0000000 \n",
            "step 99 [[0.3        0.64686342 0.4293873  0.5       ]\n",
            " [0.65012041 0.5        0.4293873  0.63605705]] 0.9158978239444003\n",
            "step 99 params [[0.3        0.64686342 0.4293873  0.5       ]\n",
            " [0.65012041 0.5        0.4293873  0.63605705]] loss 0.9158978239444003 predictions [tensor(0.63176388, requires_grad=True), tensor(0.59903249, requires_grad=True), tensor(0.63176388, requires_grad=True), tensor(0.59903249, requires_grad=True)]\n",
            "Iter:   100 | Cost: 0.5124395 | Accuracy: 1.0000000 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'state_preparation(x)\\n\\nlosses = []\\nfor i in range(400):\\n  params, loss = optimizer.step_and_cost(circuit, params)\\n  losses.append(loss)\\n  print(loss)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from pennylane import numpy as np\n",
        "\n",
        "num_wires = 4\n",
        "num_layers = 2\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_wires)\n",
        "\n",
        "coeffs = [1]\n",
        "obs = [qml.PauliZ(0) @ qml.PauliZ(1)]\n",
        "H = qml.Hamiltonian(coeffs, obs)\n",
        "\n",
        "#START HERE\n",
        "'''\n",
        "@qml.qnode(dev, interface='autograd')\n",
        "def circuit(params, x=x):\n",
        "  qml.RX(params[0], wires=0)\n",
        "  qml.RZ(params[1], wires=0)\n",
        "  for i in range(1, num_wires):\n",
        "    qml.CNOT([i-1, i])\n",
        "    qml.RX(params[0], wires=i)\n",
        "    qml.RZ(params[1], wires=i)\n",
        "  return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def circuit_0_1(params):\n",
        "  print('check i', circuit(params))\n",
        "  return (circuit(params) + 1)/2\n",
        "'''\n",
        "\n",
        "@qml.qnode(dev, interface='autograd')\n",
        "def circuit(params, x):\n",
        "  x /= np.linalg.norm(x)\n",
        "  #qml.AmplitudeEmbedding(x, wires=list(range(num_wires)))\n",
        "  qml.AngleEmbedding(features=x, wires=range(num_wires), rotation='Y')\n",
        "  qml.BasicEntanglerLayers(weights=params, wires=range(num_wires))\n",
        "\n",
        "  return qml.expval(H)\n",
        "\n",
        "  #print('state', qml.state())\n",
        "  ##print('full_circuit_1', circuit_0_1(params))\n",
        "  #return circuit_0_1(params)\n",
        "\n",
        "#def binary_cost(params):\n",
        "#  return circuit_0_1\n",
        "\n",
        "def full_circuit(params, x):\n",
        "  ###print('circuit result', circuit(params, x))\n",
        "  return (np.array(circuit(params, x)).mean() + 1)/2\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    ##print(labels, predictions)\n",
        "    for true, pred in zip(labels, predictions):\n",
        "        ##print(true, pred)\n",
        "        loss = loss + (true - pred) ** 2\n",
        "\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "def cross_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for true, pred in zip(labels, predictions):\n",
        "      #print(true*np.log(pred + 1))\n",
        "      loss = loss + true*np.log(pred) + (1-true)*np.log(1 - pred)\n",
        "    loss = - loss/len(labels)\n",
        "    return loss\n",
        "\n",
        "def accuracy(labels, predictions):\n",
        "    #loss = (labels - predictions).sum()\n",
        "    loss1 = 0\n",
        "    loss2 = 0\n",
        "    ##print('accuracy', labels, predictions)\n",
        "    for true, pred in zip(labels, predictions):\n",
        "        if true - pred < 0.5:\n",
        "            loss1 = loss1 + 1\n",
        "        if true - pred > 0.5:\n",
        "            loss2 = loss2 + 1\n",
        "    acc1 = loss1 / len(labels)\n",
        "    acc2 = loss2 / len(labels)\n",
        "    return max(acc1, acc2)\n",
        "\n",
        "def cost(params, X_batch, y_batch):\n",
        "    #predictions = full_circuit(params, X_batch)\n",
        "    ##print('X_batch.shape',X_batch.shape)\n",
        "    data_indices = [np.random.randint(0, len(X)) for _ in range(1)]\n",
        "    predictions = [full_circuit(params, X_batch[index]) for index in data_indices]\n",
        "    ##print('len(predictions)',len(predictions))\n",
        "    #predictions = full_circuit(params, X_batch.flatten())\n",
        "    ##print('Cost',y_batch, predictions)\n",
        "    return cross_loss(y_batch[data_indices], predictions)\n",
        "\n",
        "'''\n",
        "def circuit_probs(params):\n",
        "  qml.RX(params[0], wires=0)\n",
        "  qml.RZ(params[1], wires=0)\n",
        "  return qml.probs(wires=0)\n",
        "\n",
        "def cost_probs(params):\n",
        "  return circuit_probs - data'''\n",
        "\n",
        "optimizer = qml.AdamOptimizer(stepsize=0.01)\n",
        "params = np.array([[0.3, 0.5, 0.3, 0.5], [0.5, 0.5, 0.3, 0.5]], requires_grad=True)\n",
        "\n",
        "X = np.array([[1., 1., 0., 0.], [0., 0., 1., 1.], [1., 0., 1., 0.], [0., 1., 0., 1.]], requires_grad=True)\n",
        "y = np.array([0, 0, 1, 1], requires_grad=True)\n",
        "\n",
        "losses = []\n",
        "\n",
        "for it in range(100):\n",
        "  #data_index = np.random.randint(0, len(X))\n",
        "  #X_batch = X[data_index]\n",
        "  #y_batch = y[data_index]\n",
        "\n",
        "  X_batch = X\n",
        "  y_batch = y\n",
        "  params, loss = optimizer.step_and_cost(cost, params, X_batch=X_batch, y_batch=y_batch)\n",
        "  print('step', it, params, loss)\n",
        "  losses.append(loss)\n",
        "\n",
        "  predictions = [full_circuit(params, x) for x in X]\n",
        "  print('step', it, 'params', params, 'loss', loss, 'predictions', predictions)\n",
        "  #predictions = full_circuit(params, X.flatten())\n",
        "  acc = accuracy(y, predictions)\n",
        "\n",
        "  print(\n",
        "      \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "          it + 1, cost(params, X, y), acc\n",
        "      )\n",
        "  )\n",
        "\n",
        "'''state_preparation(x)\n",
        "\n",
        "losses = []\n",
        "for i in range(400):\n",
        "  params, loss = optimizer.step_and_cost(circuit, params)\n",
        "  losses.append(loss)\n",
        "  print(loss)'''\n",
        "\n",
        "\n",
        "#END HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses, label='Loss function')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ACfoCY0ujdEp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "c00fcbb0-ac28-40cf-fe85-f57af577a930"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78d61c90ea70>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAWmTzZje_Tn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}